DATA = [{"ffmpeg":"av_write_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::WriteFrame","doc":"\u003cp\u003e\nWriteFrame writes a packet to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_input_format","goRep":[{"name":"ffgopeg.v1/avformat.InputFormat::Register","doc":"\u003cp\u003e\nRegister registers the InputFormat.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_input_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_bytes_per_sample","goRep":[{"name":"ffgopeg.v1/avutil.SampleFormat::BytesPerSample","doc":"\u003cp\u003e\nBytesPerSample returns the bytes per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bytes_per_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avutil.SampleFormat::IsPlanar","doc":"\u003cp\u003e\nIsPlanar returns true if the format is planar.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bytes_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::debug_mv","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DebugMv","doc":"\u003cp\u003e\nDebugMv returns... the documentation only says \u0026#34;debug\u0026#34;\nCode outside libavcodec should access this field using AVOptions.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug_mv\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDebugMv","doc":"\u003cp\u003e\nSetDebugMv sets... the documentation only says \u0026#34;debug\u0026#34;\nCode outside libavcodec should access this field using AVOptions.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug_mv\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_trc","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ColorTrc","doc":"\u003cp\u003e\nColorTrc returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_trc\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_free_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::FreeSideData","doc":"\u003cp\u003e\nFreeSideData is a convenience function to free all the side data stored.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_free_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_subtitle_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SetSubtitleCodec","doc":"\u003cp\u003e\nSetSubtitleCodec sets the subtitle codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_subtitle_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_interleaved_write_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::InterleavedWriteFrame","doc":"\u003cp\u003e\nInterleavedWriteFrame writes a packet to an output media file ensuring correct interleaving.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_interleaved_write_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sample_fmt","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SampleFmt","doc":"\u003cp\u003e\nSampleFmt returns the audio sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetSampleFmt","doc":"\u003cp\u003e\nSetSampleFmt sets the audio sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_create_filter","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::CreateFilter","doc":"\u003cp\u003e\nCreateFilter creates and add a filter instance into an existing graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_create_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_configuration","goRep":[{"name":"ffgopeg.v1/avformat.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavformat build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_network_init","goRep":[{"name":"ffgopeg.v1/avformat.NetworkInit","doc":"\u003cp\u003e\nNetworkInit does global initialization of network components.\n\u003c/p\u003e\n\u003cp\u003e\nThis is optional, but recommended, since it avoids the overhead of implicitly doing the setup for each session.\n\u003c/p\u003e\n\u003cp\u003e\nCalling this function will become mandatory if using network protocols at some major version bump.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_network_init\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_is_initialized","goRep":[{"name":"ffgopeg.v1/swresample.Context::IsInitialized","doc":"\u003cp\u003e\nIsInitialized checks whether an swr context has been initialized or not.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_is_initialized\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_profile_name","goRep":[{"name":"ffgopeg.v1/avcodec.Codec::ProfileName","doc":"\u003cp\u003e\nProfileName returns a name for the specified profile, if available.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_profile_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::gop_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::GopSize","doc":"\u003cp\u003e\nGopSize returns the number of pictures in a group of pictures, or 0 for intra_only.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::gop_size\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetGopSize","doc":"\u003cp\u003e\nSetGopSize sets the number of pictures in a group of pictures, or 0 for intra_only.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::gop_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_output_audio_device_next","goRep":[{"name":"ffgopeg.v1/avdevice.OutputAudioDevices","doc":"\u003cp\u003e\nOutputAudioDevices returns a channel which can be used to iterate over the output audio devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.OutputAudioDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_output_audio_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_queue_attached_pictures","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::QueueAttachedPictures","doc":"\u003cp\u003e\nQueueAttachedPictures is undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_queue_attached_pictures\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_version","goRep":[{"name":"ffgopeg.v1/avdevice.Version","doc":"\u003cp\u003e\nVersion returns the libavdevice version.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::pix_fmt","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::PixFmt","doc":"\u003cp\u003e\nPixFmt returns the pixel format, see AV_PIX_FMT_xxx.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pix_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetPixFmt","doc":"\u003cp\u003e\nSetPixFmt sets the pixel format, see AV_PIX_FMT_xxx.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pix_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qmax","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::QMax","doc":"\u003cp\u003e\nQMax returns the maximum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmax\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetQMax","doc":"\u003cp\u003e\nSetQMax sets the maximum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmax\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slices","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSlices","doc":"\u003cp\u003e\nSetSlices sets the number of slices.\n\u003c/p\u003e\n\u003cp\u003e\nIndicates number of picture subdicisions. Used for parallelized decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slices\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::Slices","doc":"\u003cp\u003e\nSlices returns the number of slices.\n\u003c/p\u003e\n\u003cp\u003e\nIndicates number of picture subdicisions. Used for parallelized decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slices\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_register_all","goRep":[{"name":"ffgopeg.v1/avdevice.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes libavdevice and register all the input and output devices.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_close_input","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::Close","doc":"\u003cp\u003e\nClose closes an opened input Context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_close_input\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_move_ref","goRep":[{"name":"ffgopeg.v1/avutil.FrameMoveRef","doc":"\u003cp\u003e\nFrameMoveRef moves everythnig contained in src to dst and reset src.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_move_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_close","goRep":[{"name":"ffgopeg.v1/swresample.Context::Close","doc":"\u003cp\u003e\nClose closes the context so that swr_is_initialized() returns 0.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bits_per_raw_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BitsPerRawSample","doc":"\u003cp\u003e\nBitsPerRawSample returns the bits per sample/pixel of internal libavcodec pixel/sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_raw_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBitsPerRawSample","doc":"\u003cp\u003e\nSetBitsPerRawSample sets the bits per sample/pixel of internal libavcodec pixel/sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_raw_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_change","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ParserChange","doc":"\u003cp\u003e\nParserChange is not yet completely implemented.\nC-Function: av_parser_change\nTODO\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_send_frame","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SendFrame","doc":"\u003cp\u003e\nSendFrame sends a frame as input to the encoder.\nC-Function: avcodec_send_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_space","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ColorSpace","doc":"\u003cp\u003e\nColorSpace returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_space\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_next","goRep":[{"name":"ffgopeg.v1/avcodec.RegisteredCodecParsers","doc":"\u003cp\u003e\nRegisteredCodecParsers returns a channel which can be used to iterate over the registered CodecParser.\nC-Function: av_parser_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor cc := range avcodec.RegisteredCodecDescriptors() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVCodecContext::colorspace","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Colorspace","doc":"\u003cp\u003e\nColorspace returns the YUV colorspace type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::colorspace\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetColorspace","doc":"\u003cp\u003e\nSetColorspace sets the YUV colorspace type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::colorspace\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_process_command","goRep":[{"name":"ffgopeg.v1/avfilter.FilterContext::ProcessCommand","doc":"\u003cp\u003e\nProcessCommand makes the filter instance process a command.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_process_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_configuration","goRep":[{"name":"ffgopeg.v1/avcodec.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavcodec build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_all","goRep":[{"name":"ffgopeg.v1/avformat.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes libavformat and register all the muxers, demuxers and protocols.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_pause","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::ReadPause","doc":"\u003cp\u003e\nReadPause pauses a network-based stream (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_pause\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_set_qp_table","goRep":[{"name":"ffgopeg.v1/avutil.Frame::SetQpTable","doc":"\u003cp\u003e\nSetQpTable sets the qp table.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_set_qp_table\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_plane_buffer","goRep":[{"name":"ffgopeg.v1/avutil.Frame::PlaneBuffer","doc":"\u003cp\u003e\nPlaneBuffer gets the buffer reference a given data plane is stored in.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_plane_buffer\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_convert","goRep":[{"name":"ffgopeg.v1/swresample.Context::Convert","doc":"\u003cp\u003e\nConvert core conversion functions. Convert audio\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_convert\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_normalizeVec","goRep":[{"name":"ffgopeg.v1/swscale.Vector::Normalize","doc":"\u003cp\u003e\nNormalize scales all the coefficients of a so that their sum equals height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_normalizeVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_is_encoder","goRep":[{"name":"ffgopeg.v1/avcodec.Codec::IsEncoder","doc":"\u003cp\u003e\nIsEncoder returns true if the codec is an encoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_is_encoder\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::profile","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Profile","doc":"\u003cp\u003e\nProfile returns somthing undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::profile\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetProfile","doc":"\u003cp\u003e\nSetProfile sets somthing undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::profile\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_query_codec","goRep":[{"name":"ffgopeg.v1/avformat.AvformatQueryCodec","doc":"\u003cp\u003e\nTest if the given container can store a codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_query_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_end_pts","goRep":[{"name":"ffgopeg.v1/avformat.Stream::StreamGetEndPts","doc":"\u003cp\u003e\nStreamGetEndPts returns the pts of the last muxed packet + its duration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_end_pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_initial_buffer_occupancy","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcInitialBufferOccupancy","doc":"\u003cp\u003e\nRcInitialBufferOccupancy returns the number of bits which should be loaded into the rx buffer before decoding starts.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_initial_buffer_occupancy\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcInitialBufferOccupancy","doc":"\u003cp\u003e\nSetRcInitialBufferOccupancy sets the number of bits which should be loaded into the rx buffer before decoding starts.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_initial_buffer_occupancy\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_ref","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Ref","doc":"\u003cp\u003e\nRef sets up a new reference to the data described by a given packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_tag","goRep":[{"name":"ffgopeg.v1/avformat.AvCodecGetTag","doc":"\u003cp\u003e\nGet the codec tag for the given codec id id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_tag\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_pkt_dump_log2","goRep":[{"name":"ffgopeg.v1/avformat.AvPktDumpLog2","doc":"\u003cp\u003e\nSend a nice dump of a packet to the log.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_pkt_dump_log2\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_align_dimensions","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::AlignDimensions","doc":"\u003cp\u003e\nAlignDimensions modifies width and height values so that they will result in a memory buffer that is acceptable for the codec if you do not use any horizontal padding.\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\nC-Function: avcodec_align_dimensions\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::coded_width","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CodedWidth","doc":"\u003cp\u003e\nCodedWidth returns the bitstream width.\nIt may be different from the raw width. When the decoded frame is cropped before being output or lowres is enabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_width\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetCodedWidth","doc":"\u003cp\u003e\nSetCodedWidth sets the bitstream width.\nIt may be different from the raw width. When the decoded frame is cropped before being output or lowres is enabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_width\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_primaries","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ColorPrimaries","doc":"\u003cp\u003e\nColorPrimaries returns the chromaticity coordinates of the source primaries.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_primaries\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetColorPrimaries","doc":"\u003cp\u003e\nSetColorPrimaries sets the chromaticity coordinates of the source primaries.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_primaries\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::dia_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DiaSize","doc":"\u003cp\u003e\nDiaSize returns ME diamod size and shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dia_size\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDiaSize","doc":"\u003cp\u003e\nSetDiaSize sets ME diamod size and shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dia_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_subtitle_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SubtitleCodec","doc":"\u003cp\u003e\nSubtitleCodec returns the subtitle codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_subtitle_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_media_type_string","goRep":[{"name":"ffgopeg.v1/avutil.MediaTypeString","doc":"\u003cp\u003e\nMediaTypeString returns a string describing the media_type enum, NULL if media_type is unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_media_type_string\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_buffer","goRep":[{"name":"ffgopeg.v1/avutil.Frame::NewBuffer","doc":"\u003cp\u003e\nNewBuffer allocates new buffer(s) for audio or video data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_buffer\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_alt_sample_fmt","goRep":[{"name":"ffgopeg.v1/avutil.SampleFormat::Alternative","doc":"\u003cp\u003e\nAlternative returns the planar\u0026lt;-\u0026gt;packed alternative form of the given sample format, or AV_SAMPLE_FMT_NONE on error.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_alt_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::audio_service_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::AudioServiceType","doc":"\u003cp\u003e\nAudioServiceType returns the type of service that the audio stream conveys.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::audio_service_type\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetAudioServiceType","doc":"\u003cp\u003e\nSetAudioServiceType sets the type of service that the audio stream conveys.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::audio_service_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slice_count","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSliceCount","doc":"\u003cp\u003e\nSetSliceCount sets the slice count.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_count\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SliceCount","doc":"\u003cp\u003e\nSliceCount returns the slice count.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::Parse","doc":"\u003cp\u003e\nParse adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse\n\u003c/p\u003e\n"}]},{"ffmpeg":"avpriv_frame_get_metadatap","goRep":[{"name":"ffgopeg.v1/avutil.Frame::Metadatap","doc":"\u003cp\u003e\nMetadatap returns metadatap.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avpriv_frame_get_metadatap\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::field_order","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::FieldOrder","doc":"\u003cp\u003e\nFieldOrder returns the order of the fields in interlaced video.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::field_order\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::width","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Width","doc":"\u003cp\u003e\nWidth returns the width of the video frame in pixels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::width\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::size","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Size","doc":"\u003cp\u003e\nSize returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::size\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_license","goRep":[{"name":"ffgopeg.v1/avformat.License","doc":"\u003cp\u003e\nLicense returns the libavformat license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_next","goRep":[{"name":"ffgopeg.v1/avcodec.RegisteredCodecs","doc":"\u003cp\u003e\nRegisteredCodecs returns a channel which can be used to iterate over the registered codecs.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor codec := range avcodec.RegisteredCodecs() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVCodecContext::codec_id","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CodecID","doc":"\u003cp\u003e\nCodecID returns the codec id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::codec_id\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::flags","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Flags","doc":"\u003cp\u003e\nFlags returns the flags AV_CODEC_FLAG_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetFlags","doc":"\u003cp\u003e\nSetFlags set the flags AV_CODEC_FLAG_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::request_sample_fmt","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RequestSampleFmt","doc":"\u003cp\u003e\nRequestSampleFmt returns the desired sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::request_sample_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRequestSampleFmt","doc":"\u003cp\u003e\nSetRequestSampleFmt sets the desired sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::request_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_side_data","goRep":[{"name":"ffgopeg.v1/avutil.Frame::SideData","doc":"\u003cp\u003e\nSideData returns the frames sidedata.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_inject_silence","goRep":[{"name":"ffgopeg.v1/swresample.Context::InjectSilence","doc":"\u003cp\u003e\nInjectSilence injects the specified number of silence samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_inject_silence\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_channel_mapping","goRep":[{"name":"ffgopeg.v1/swresample.Context::SetChannelMapping","doc":"\u003cp\u003e\nSetChannelMapping sets a customized input channel mapping.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_channel_mapping\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::idct_algo","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IdctAlgo","doc":"\u003cp\u003e\nIdctAlgo returns the IDCT algorithm, see FF_IDCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::idct_algo\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetIdctAlgo","doc":"\u003cp\u003e\nSetIdctAlgo sets the IDCT algorithm, see FF_IDCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::idct_algo\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_lowres","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Lowres","doc":"\u003cp\u003e\nLowres returns the low resolution decoding.\n1 equals 1/2 size. 2 equals 1/4 size.\nC-Function: av_codec_get_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qblur","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::QBlur","doc":"\u003cp\u003e\nQBlur returns the amount of qscale smoothing over time.\n(0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qblur\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetQBlur","doc":"\u003cp\u003e\nSetQBlur sets the amount of qscale smoothing over time.\n(0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qblur\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_register","goRep":[{"name":"ffgopeg.v1/avfilter.Filter::Register","doc":"\u003cp\u003e\nRegister registers a filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_register\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_license","goRep":[{"name":"ffgopeg.v1/avdevice.License","doc":"\u003cp\u003e\nLicense returns the libavdevice license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_request_oldest","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::RequestOldestlink","doc":"\u003cp\u003e\nRequestOldestlink requests a frame on the oldest sink\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_request_oldest\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_send_command","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::SendCommand","doc":"\u003cp\u003e\nSendCommand sends a command to one or more filter instances.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_send_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_output_timestamp","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::OutputTimestamp","doc":"\u003cp\u003e\nOutputTimestamp returns timing information for the data currently output.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_output_timestamp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hwaccel_next","goRep":[{"name":"ffgopeg.v1/avcodec.RegisteredHWAccels","doc":"\u003cp\u003e\nRegisteredHWAccels returns a channel which can be used to iterate over the registered HWAccel.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hwaccel_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor hwa := range avcodec.RegisteredHWAccels() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_pre_cmp","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MePreCmp","doc":"\u003cp\u003e\nMePreCmp returns the motion estimation prepass comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_pre_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMePreCmp","doc":"\u003cp\u003e\nSetMePreCmp sets the motion estimation prepass comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_pre_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::strict_std_compliance","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetStrictStdCompliance","doc":"\u003cp\u003e\nSetStrictStdCompliance sets the strictness to follow the standard (MPEG-4, ...).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::strict_std_compliance\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::StrictStdCompliance","doc":"\u003cp\u003e\nStrictStdCompliance returns the strictness to follow the standard (MPEG-4, ...).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::strict_std_compliance\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_input_audio_device_next","goRep":[{"name":"ffgopeg.v1/avdevice.InputAudioDevices","doc":"\u003cp\u003e\nInputAudioDevices returns a channel which can be used to iterate over the input audio devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.InputAudioDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_input_audio_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_primaries","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ColorPrimaries","doc":"\u003cp\u003e\nColorPrimaries returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_primaries\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::pos","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Pos","doc":"\u003cp\u003e\nPos returns the byte position in stream, -1 if unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::pos\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_app_to_dev_control_message","goRep":[{"name":"ffgopeg.v1/avdevice.AppToDevControlMessage","doc":"\u003cp\u003e\nAppToDevControlMessage sends control message from application to device.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_app_to_dev_control_message\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hex_dump_log","goRep":[{"name":"ffgopeg.v1/avformat.AvHexDumpLog","doc":"\u003cp\u003e\nSend a nice hexadecimal dump of a buffer to the log.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hex_dump_log\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_fast_padded_mallocz","goRep":[{"name":"ffgopeg.v1/avcodec.FastPaddedMallocz","doc":"\u003cp\u003e\nFastPaddedMallocz allocates a buffer, reusing the given one if large enough and initializes the data with 0.\nThe buffer has additional FF_INPUT_BUFFER_PADDING_SIZE at the end which will always be 0.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_fast_padded_mallocz\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_version","goRep":[{"name":"ffgopeg.v1/avcodec.Version","doc":"\u003cp\u003e\nVersion returns the LIBAvCODEC_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::debug","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Debug","doc":"\u003cp\u003e\nDebug returns... the documentation only says \u0026#34;debug\u0026#34;\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDebug","doc":"\u003cp\u003e\nSetDebug sets... the documentation only says \u0026#34;debug\u0026#34;\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::nsse_weight","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::NsseWeight","doc":"\u003cp\u003e\nNsseWeight returns the noise vs sse weight for the nsse comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::nsse_weight\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_sample_fmt_name","goRep":[{"name":"ffgopeg.v1/avutil.SampleFormat::Name","doc":"\u003cp\u003e\nName returns the sample format name.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_sample_fmt_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_link","goRep":[{"name":"ffgopeg.v1/avfilter.Link","doc":"\u003cp\u003e\nLink links two filters together.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_link\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_configuration","goRep":[{"name":"ffgopeg.v1/swresample.Configuration","doc":"\u003cp\u003e\nConfiguration returns the build time configuration of swresample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_init","goRep":[{"name":"ffgopeg.v1/swresample.Context::Init","doc":"\u003cp\u003e\nInit initializes the context after user parameters have been set.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_init\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_unpack_dictionary","goRep":[{"name":"ffgopeg.v1/avcodec.UnpackDictionary","doc":"\u003cp\u003e\nUnpackDictionary unpacks a dictionary from side_data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_unpack_dictionary\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::lumi_masking","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::LumiMasking","doc":"\u003cp\u003e\nLumiMasking retunrs the level of luminance masking.\n0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::lumi_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetLumiMasking","doc":"\u003cp\u003e\nSetLumiMasking retunrs the level of luminance masking.\n0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::lumi_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::refs","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Refs","doc":"\u003cp\u003e\nRefs returns the number reference frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refs\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRefs","doc":"\u003cp\u003e\nSetRefs sets the number reference frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refs\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_move_ref","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::MoveRef","doc":"\u003cp\u003e\nMoveRef moves every field in src to dst and reset src.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_move_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::initial_padding","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::InitialPadding","doc":"\u003cp\u003e\nInitialPadding returns the amount of padding (in samples) inserted by the encoder at the beginning of the audio. I.e. this number of leading decoded samples must be discarded by the caller to get the original audio without leading padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::initial_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_copy_packet_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::CopyPacketSideData","doc":"\u003cp\u003e\nCopyPacketSideData copies packet side data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_copy_packet_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_config","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::GraphConfig","doc":"\u003cp\u003e\nGraphConfig checks validity and configure all the links and formats in the graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_config\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_packed_sample_fmt","goRep":[{"name":"ffgopeg.v1/avutil.SampleFormat::Packed","doc":"\u003cp\u003e\nPacked returns the packed variant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_packed_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::active_thread_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ActiveThreadType","doc":"\u003cp\u003e\nActiveThreadType returns which multithreading methods are used by the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::active_thread_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_trc","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ColorTrc","doc":"\u003cp\u003e\nColorTrc returns the color transfer characteristic.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_trc\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetColorTrc","doc":"\u003cp\u003e\nSetColorTrc sets the color transfer characteristic.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_trc\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::max_b_frames","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MaxBFrames","doc":"\u003cp\u003e\nMaxBFrames returns the maximum nomber of B-frames between non-B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nNote: The output will be delayed by max_b_frames+1 relative to the input.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_b_frames\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMaxBFrames","doc":"\u003cp\u003e\nSetMaxBFrames sets the maximum nomber of B-frames between non-B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nNote: The output will be delayed by max_b_frames+1 relative to the input.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_b_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_range","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MeRange","doc":"\u003cp\u003e\nMeRange returns the maximum motion estimation search range in subpel units.\nIf 0 then no limit.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_range\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMeRange","doc":"\u003cp\u003e\nSetMeRange sets the maximum motion estimation search range in subpel units.\nIf 0 then no limit.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_version","goRep":[{"name":"ffgopeg.v1/avfilter.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVFILTER_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_new_stream","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::NewStream","doc":"\u003cp\u003e\nNewStream adds a new stream to a media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_new_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bits_per_coded_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BitsPerCodedSample","doc":"\u003cp\u003e\nBitsPerCodedSample returns the bits per sample/pixel from the demuxer (needed for huffyuv).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_coded_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBitsPerCodedSample","doc":"\u003cp\u003e\nSetBitsPerCodedSample set the bits per sample/pixel from the demuxer (needed for huffyuv).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_coded_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::chroma_sample_location","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ChromaSampleLocation","doc":"\u003cp\u003e\nChromaSampleLocation returns the location of chroma samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::chroma_sample_location\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetChromaSampleLocation","doc":"\u003cp\u003e\nSetChromaSampleLocation sets the location of chroma samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::chroma_sample_location\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::ildct_cmp","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IldctCmp","doc":"\u003cp\u003e\nIldctCmp returns the interlaced DCT comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ildct_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetIldctCmp","doc":"\u003cp\u003e\nSetIldctCmp sets the interlaced DCT comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ildct_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_id","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::CodecID","doc":"\u003cp\u003e\nCodecID returns the id of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_id\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::profile","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Profile","doc":"\u003cp\u003e\nProfile returns the codec-specific bitstream restrictions that the stream conforms to.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::profile\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_x_if_null","goRep":[{"name":"ffgopeg.v1/avutil.XIfNull","doc":"\u003cp\u003e\nXIfNull returns x default pointer in case p is NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_x_if_null\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_chroma_sub_sample","goRep":[{"name":"ffgopeg.v1/avutil.PixelFormat::ChromaSubSample","doc":"\u003cp\u003e\nChromaSubSample grants access log2_chroma_w log2_chroma_h from the pixel format AvPixFmtDescriptor.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_chroma_sub_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avutil.PixelFormat::ToCodecTag","doc":"\u003cp\u003e\nToCodecTag returns a value representing the fourCC code associated to the pixel format pix_fmt, or 0 if no associated fourCC code can be found.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_chroma_sub_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_free","goRep":[{"name":"ffgopeg.v1/swresample.Context::Free","doc":"\u003cp\u003e\nFree frees Context destructor functions. Free the given Context and set the pointer to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::coded_height","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CodedHeight","doc":"\u003cp\u003e\nCodedHeight returns the bitstream height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetCodedHeight","doc":"\u003cp\u003e\nSetCodedHeight sets the bitstream height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetHeight","doc":"\u003cp\u003e\nSetHeight sets the raw image height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacketSideData::data","goRep":[{"name":"ffgopeg.v1/avcodec.PacketSideData::Data","doc":"\u003cp\u003e\nData returns the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacketSideData::data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_input_video_device_next","goRep":[{"name":"ffgopeg.v1/avdevice.InputVideoDevices","doc":"\u003cp\u003e\nInputVideoDevices returns a channel which can be used to iterate over the input video devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.InputVideoDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_input_video_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_config_links","goRep":[{"name":"ffgopeg.v1/avfilter.FilterContext::ConfigLinks","doc":"\u003cp\u003e\nConfigLinks negotiates the media format, dimensions, etc of all inputs to a filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_config_links\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_frame_filename","goRep":[{"name":"ffgopeg.v1/avformat.AvGetFrameFilename","doc":"\u003cp\u003e\nint av_get_frame_filename (char *buf, int buf_size, const char *path, int number)\nReturn in \u0026#39;buf\u0026#39; the path with \u0026#39;d\u0026#39; replaced by a number.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_frame_filename\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_guess_frame_rate","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::GuessFrameRate","doc":"\u003cp\u003e\nGuessFrameRate guesses the frame rate, based on both the container and codec information.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_guess_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_license","goRep":[{"name":"ffgopeg.v1/swresample.License","doc":"\u003cp\u003e\nLicense returns the swresample license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_matrix","goRep":[{"name":"ffgopeg.v1/swresample.Context::SetMatrix","doc":"\u003cp\u003e\nSetMatrix sets a customized remix matrix.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_matrix\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::b_quant_offset","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BQuantOffset","doc":"\u003cp\u003e\nBQuantOffset return the qscale offset between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBQuantOffset","doc":"\u003cp\u003e\nSetBQuantOffset return the qscale offset between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_override_count","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcOverrideCount","doc":"\u003cp\u003e\nRcOverrideCount returns ratecontrol override, see RcOverride.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_override_count\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcOverrideCount","doc":"\u003cp\u003e\nSetRcOverrideCount sets ratecontrol override, see RcOverride.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_override_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_rescale_ts","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::RescaleTs","doc":"\u003cp\u003e\nRescaleTs converts valid timing fields (timestamps / durations) in a packet from one timebase to another.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_rescale_ts\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_alloc_filter","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::NewFilterContext","doc":"\u003cp\u003e\nNewFilterContext creates a new filter instance in a filter graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_alloc_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_lmax","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MbLMax","doc":"\u003cp\u003e\nMbLMax returns the maximum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmax\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMbLMax","doc":"\u003cp\u003e\nSetMbLMax returns the maximum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmax\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_sdp_create","goRep":[{"name":"ffgopeg.v1/avformat.AvSdpCreate","doc":"\u003cp\u003e\nGenerate an SDP for an RTP session.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_sdp_create\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_pix_fmt_loss","goRep":[{"name":"ffgopeg.v1/avutil.GetPixFmtLoss","doc":"\u003cp\u003e\nGetPixFmtLoss returns what kind of losses will occur when converting from one specific pixel format to another.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_pix_fmt_loss\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_is_writable","goRep":[{"name":"ffgopeg.v1/avutil.Frame::IsWritable","doc":"\u003cp\u003e\nIsWritable checks if the frame data is writable.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_is_writable\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_register","goRep":[{"name":"ffgopeg.v1/avcodec.RegisterCodec","doc":"\u003cp\u003e\nRegisterCodec registers the codec and initializes libavcodec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_register\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_pkt_timebase","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetPktTimebase","doc":"\u003cp\u003e\nSetPktTimebase sets the packet timebase.\nC-Function: av_codec_set_pkt_timebase\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_version","goRep":[{"name":"ffgopeg.v1/swresample.Version","doc":"\u003cp\u003e\nVersion returns the swresample version.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_top","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSkipTop","doc":"\u003cp\u003e\nSetSkipTop sets the number of macroblock rows at the top which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_top\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SkipTop","doc":"\u003cp\u003e\nSkipTop returns the number of macroblock rows at the top which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_top\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_make_writable","goRep":[{"name":"ffgopeg.v1/avutil.Frame::MakeWritable","doc":"\u003cp\u003e\nMakeWritable ensures that the frame data is writable, avoiding data copy if possible.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_make_writable\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_getColorspaceDetails","goRep":[{"name":"ffgopeg.v1/swscale.ColorspaceDetails","doc":"\u003cp\u003e\nColorspaceDetails returns the colorspace details.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_getColorspaceDetails\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_register_all","goRep":[{"name":"ffgopeg.v1/avcodec.RegisterAll","doc":"\u003cp\u003e\nRegisterAll registers all the codecs, parsers and bitstream filters which were enabled at configuration time.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mv0_threshold","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Mv0Threshold","doc":"\u003cp\u003e\nMv0Threshold returns the mv0 threshold.\nValue depends on the compare function used for follpel ME.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mv0_threshold\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMv0Threshold","doc":"\u003cp\u003e\nSetMv0Threshold sets the mv0 threshold.\nValue depends on the compare function used for follpel ME.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mv0_threshold\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qmin","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::QMin","doc":"\u003cp\u003e\nQMin returns the minimum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmin\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetQMin","doc":"\u003cp\u003e\nSetQMin sets the minimum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmin\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_seek_preroll","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SeekPreroll","doc":"\u003cp\u003e\nSeekPreroll returns something undocumented.\nC-Function: av_codec_get_seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_dict_count","goRep":[{"name":"ffgopeg.v1/avformat.Dictionary::Count","doc":"\u003cp\u003e\nCount returns the number of entries in dictionary.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dict_count\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avformat.Dictionary::Get","doc":"\u003cp\u003e\nGet returns a dictionary entry with matching key.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dict_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_set_r_frame_rate","goRep":[{"name":"ffgopeg.v1/avformat.Stream::StreamSetRFrameRate","doc":"\u003cp\u003e\nStreamSetRFrameRate does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_set_r_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::dct_algo","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DctAlgo","doc":"\u003cp\u003e\nDctAlgo returns the DCT algorithm, see FF_DCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dct_algo\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDctAlgo","doc":"\u003cp\u003e\nSetDctAlgo sets the DCT algorithm, see FF_DCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dct_algo\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::refcounted_frames","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RefcountedFrames","doc":"\u003cp\u003e\nRefcountedFrames returns the number of references of audio and video frames.\n\u003c/p\u003e\n\u003cp\u003e\nIf non-zero, the decoded audio and video frames returned from avcodec_decode_video2() and avcodec_decode_audio4() are reference-counted and are valid indefinitely.\n\u003c/p\u003e\n\u003cp\u003e\nThe caller must free them with av_frame_unref() when they are not needed anymore. Otherwise, the decoded frames must not be freed by the caller and are only valid until the next decode call.\n\u003c/p\u003e\n\u003cp\u003e\nThis is always automatically enabled if avcodec_receive_frame() is used.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refcounted_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sample_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SampleRate","doc":"\u003cp\u003e\nSampleRate returns the number of samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetSampleRate","doc":"\u003cp\u003e\nSetSampleRate sets the number of samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_unref","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Unref","doc":"\u003cp\u003e\nUnref wipes a packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_unref\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_license","goRep":[{"name":"ffgopeg.v1/avutil.License","doc":"\u003cp\u003e\nLicense returns the libavutil license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeFilter","goRep":[{"name":"ffgopeg.v1/swscale.Filter::Free","doc":"\u003cp\u003e\nFree frees the filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeFilter\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::intra_dc_precision","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IntraDcPrecision","doc":"\u003cp\u003e\nIntraDcPrecision returns the precision of the intra DC coefficient - 8.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::intra_dc_precision\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetIntraDcPrecision","doc":"\u003cp\u003e\nSetIntraDcPrecision sets the precision of the intra DC coefficient - 8.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::intra_dc_precision\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_max_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcMaxRate","doc":"\u003cp\u003e\nRcMaxRate returns the maximum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcMaxRate","doc":"\u003cp\u003e\nSetRcMaxRate sets the maximum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_match_stream_specifier","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::MatchStreamSpecifier","doc":"\u003cp\u003e\nMatchStreamSpecifier checks if the stream st contained in s is matched by the stream specifier spec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_match_stream_specifier\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_probe_score","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::ProbeScore","doc":"\u003cp\u003e\nProbeScore returns the probe score.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_probe_score\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_init_packet","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Init","doc":"\u003cp\u003e\nInit initializes optional fields of a packet with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_init_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::SideData","doc":"\u003cp\u003e\nSideData returns the side data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse_ptr","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::ParsePtr","doc":"\u003cp\u003e\nParsePtr adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse_ptr\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_descriptor_next","goRep":[{"name":"ffgopeg.v1/avcodec.RegisteredCodecDescriptors","doc":"\u003cp\u003e\nRegisteredCodecDescriptors returns a channel which can be used to iterate over the registered CodecDescriptor.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_descriptor_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor cc := range avcodec.RegisteredCodecDescriptors() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"avcodec_send_packet","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SendPacket","doc":"\u003cp\u003e\nSendPacket sends a packet as input to the decoder.\nC-Function: avcodec_send_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_idct","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSkipIdct","doc":"\u003cp\u003e\nSetSkipIdct sets the skip IDCT/dequantization for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_idct\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SkipIdct","doc":"\u003cp\u003e\nSkipIdct returns the skip IDCT/dequantization for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_idct\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sub_charenc_mode","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SubCharencMode","doc":"\u003cp\u003e\nSubCharencMode returns the subtitles character encoding mode.\n\u003c/p\u003e\n\u003cp\u003e\nFormats or codecs might be adjusting this settings (if they are doing the conversion themselves for instance).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sub_charenc_mode\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedEndiannessConversion","goRep":[{"name":"ffgopeg.v1/swscale.IsSupportedEndiannessConversion","doc":"\u003cp\u003e\nIsSupportedEndiannessConversion returns true if endianess conversion is supported.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedEndiannessConversion\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_decision","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MbDecision","doc":"\u003cp\u003e\nMbDecision returns the macroblock decision mode.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_decision\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMbDecision","doc":"\u003cp\u003e\nSetMbDecision sets the macroblock decision mode.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_decision\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_sub_cmp","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MeSubCmp","doc":"\u003cp\u003e\nMeSubCmp returns the subpixel motion comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_sub_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMeSubCmp","doc":"\u003cp\u003e\nSetMeSubCmp sets the subpixel motion comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_sub_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_new_packet","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::NewPacket","doc":"\u003cp\u003e\nNewPacket allocates the payload of a packet and initialize its fields with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_new_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_configuration","goRep":[{"name":"ffgopeg.v1/avdevice.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavdevice build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_version","goRep":[{"name":"ffgopeg.v1/avformat.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVFORMAT_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedOutput","goRep":[{"name":"ffgopeg.v1/swscale.IsSupportedOutput","doc":"\u003cp\u003e\nIsSupportedOutput returns true if pix_fmt is a supported output format, false otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedOutput\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bit_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BitRate","doc":"\u003cp\u003e\nBitRate returns the average bit rate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBitRate","doc":"\u003cp\u003e\nSetBitRate sets the average bit rate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_max_available_vbv_use","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcMaxAvailableVbvUse","doc":"\u003cp\u003e\nRcMaxAvailableVbvUse returns the ratecontrol attempt to use, at maximum, of what can be used without an underflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_available_vbv_use\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcMaxAvailableVbvUse","doc":"\u003cp\u003e\nSetRcMaxAvailableVbvUse sets the ratecontrol attempt to use, at maximum, of what can be used without an underflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_available_vbv_use\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_count","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetThreadCount","doc":"\u003cp\u003e\nSetThreadCount sets the thread count, which is used to decide how many independent tasks should be passed to execute().\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_count\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::ThreadCount","doc":"\u003cp\u003e\nThreadCount returns the thread count, which is used to decide how many independent tasks should be passed to execute().\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_free","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::Free","doc":"\u003cp\u003e\nFree frees a graph, destroy its links, and set *graph to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_seek_file","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SeekFile","doc":"\u003cp\u003e\nSeekFile seeks to timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_seek_file\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::sample_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::SampleRate","doc":"\u003cp\u003e\nSampleRate returns the number of audio samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::sample_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_merge_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::MergeSideData","doc":"\u003cp\u003e\nMergeSideData does something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_merge_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_configuration","goRep":[{"name":"ffgopeg.v1/avfilter.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavfilter build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_find_default_stream_index","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::FindDefaultStreamIndex","doc":"\u003cp\u003e\nFindDefaultStreamIndex returns the default stream index.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_find_default_stream_index\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_inject_global_side_data","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::InjectGlobalSideData","doc":"\u003cp\u003e\nInjectGlobalSideData will cause global side data to be injected in the next packet of each stream as well as after any subsequent seek.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_inject_global_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_probe_input_buffer2","goRep":[{"name":"ffgopeg.v1/avformat.IOContext::ProbeInputBuffer","doc":"\u003cp\u003e\nProbeInputBuffer probes a bytestream to determine the input format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_probe_input_buffer2\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_get_delay","goRep":[{"name":"ffgopeg.v1/swresample.Context::GetDelay","doc":"\u003cp\u003e\nGetDelay gets the delay the next input sample will experience relative to the next output sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_get_delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"GoString","goRep":[{"name":"ffgopeg.v1/swscale.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libswscale build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: GoString\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/swscale.License","doc":"\u003cp\u003e\nLicense returns the libswscale license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: GoString\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::keyint_min","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::KeyintMin","doc":"\u003cp\u003e\nKeyintMin returns the minimum GOP size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::keyint_min\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetKeyintMin","doc":"\u003cp\u003e\nSetKeyintMin sets the minimum GOP size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::keyint_min\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::block_align","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::BlockAlign","doc":"\u003cp\u003e\nBlockAlign returns the number of bytes per coded audio frame, required by some formats.\n\u003c/p\u003e\n\u003cp\u003e\nCorresponds to nBlockAlign in WAVEFORMATEX.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::block_align\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::sample_aspect_ratio","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::SampleAspectRatio","doc":"\u003cp\u003e\nSampleAspectRatio returns the aspect ratio (width / height) which a single pixel should have when displayed.\n\u003c/p\u003e\n\u003cp\u003e\nWhen the aspect ratio is unknown / undefined, the numerator should be set to 0 (the denominator may have any value).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::sample_aspect_ratio\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hex_dump","goRep":[{"name":"ffgopeg.v1/avformat.AvHexDump","doc":"\u003cp\u003e\nSend a nice hexadecimal dump of a buffer to the specified file stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hex_dump\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_count","goRep":[{"name":"ffgopeg.v1/avfilter.FilterPadCount","doc":"\u003cp\u003e\nFilterPadCount gets the number of elements in a NULL-terminated array of FilterPads (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"swscale_version","goRep":[{"name":"ffgopeg.v1/swscale.Version","doc":"\u003cp\u003e\nVersion returns the LIBSWSCALE_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function:\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swscale_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeVec","goRep":[{"name":"ffgopeg.v1/swscale.Vector::Free","doc":"\u003cp\u003e\nFree frees the vector.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"avsubtitle_free","goRep":[{"name":"ffgopeg.v1/avcodec.Subtitle::Free","doc":"\u003cp\u003e\nFree frees all allocated data of the Subtitle.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avsubtitle_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_planar_sample_fmt","goRep":[{"name":"ffgopeg.v1/avutil.SampleFormat::Planar","doc":"\u003cp\u003e\nPlanar returns the planar variant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_planar_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_scale","goRep":[{"name":"ffgopeg.v1/swscale.Context::Scale","doc":"\u003cp\u003e\nScale scales the image slice in srcSlice and put the resulting scaled slice in the image in dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_scale\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bidir_refine","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BidirRefine","doc":"\u003cp\u003e\nBidirRefine returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bidir_refine\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBidirRefine","doc":"\u003cp\u003e\nSetBidirRefine sets something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bidir_refine\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_open2","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Open","doc":"\u003cp\u003e\nOpen initializes the CodecContext to use the given Codec.\nC-Function: avcodec_open2\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_fill_audio_frame","goRep":[{"name":"ffgopeg.v1/avcodec.Frame::FillAudioFrame","doc":"\u003cp\u003e\nFillAudioFrame fills the Frame audio data and linesize pointers.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_fill_audio_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_copy_props","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::CopyProps","doc":"\u003cp\u003e\nCopyProps copies only \u0026#34;properties\u0026#34; fields from src to dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_copy_props\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_r_frame_rate","goRep":[{"name":"ffgopeg.v1/avformat.Stream::StreamGetRFrameRate","doc":"\u003cp\u003e\nStreamGetRFrameRate does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_r_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_seek_preroll","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSeekPreroll","doc":"\u003cp\u003e\nSetSeekPreroll sets something undocumented.\nC-Function: av_codec_set_seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bits_per_raw_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::BitsPerRawSample","doc":"\u003cp\u003e\nBitsPerRawSample returns the number of valid bits in each output sample.\n\u003c/p\u003e\n\u003cp\u003e\nIf the sample format has more bits, the least significant bits are additional padding bits, which are always 0. Use right shifts to reduce the sample to its actual size. For example, audio formats with 24 bit samples will have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32. To get the original sample use \u0026#34;(int32_t)sample \u0026gt;\u0026gt; 8\u0026#34;.\u0026#34;\n\u003c/p\u003e\n\u003ch3 id=\"hdr-For_ADPCM_this_might_be_12_or_16_or_similar_Can_be_0\"\u003eFor ADPCM this might be 12 or 16 or similar Can be 0\u003c/h3\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bits_per_raw_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_pkt_dump2","goRep":[{"name":"ffgopeg.v1/avformat.AvPktDump2","doc":"\u003cp\u003e\nSend a nice dump of a packet to the specified file stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_pkt_dump2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_interleaved_write_uncoded_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::InterleavedWriteUncodedFrame","doc":"\u003cp\u003e\nInterleavedWriteUncodedFrame writes a uncoded frame to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_interleaved_write_uncoded_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_from_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::PacketFromData","doc":"\u003cp\u003e\nPacketFromData initializes a reference-counted packet from av_malloc()ed data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_from_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_audio_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::AudioCodec","doc":"\u003cp\u003e\nAudioCodec returns the audio codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_audio_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::channels","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Channels","doc":"\u003cp\u003e\nChannels returns the number of audio channels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::channels\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_parse2","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Parse","doc":"\u003cp\u003e\nParse is not yet completely implemented.\nC-Function: av_parser_parse2\nTODO\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_lowres","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetLowres","doc":"\u003cp\u003e\nSetLowres sets the low resolution decoding.\n1 equals 1/2 size. 2 equals 1/4 size.\nC-Function: av_codec_set_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::ticks_per_frame","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetTicksPerFrame","doc":"\u003cp\u003e\nSetTicksPerFrame sets the ticks per frame.\n\u003c/p\u003e\n\u003cp\u003e\nFor some codecs, the time base is closer to the field rate than the frame rate.\n\u003c/p\u003e\n\u003cp\u003e\nMost notably, H.264 and MPEG-2 specify time_base as half of frame duration if no telecine is used ...\n\u003c/p\u003e\n\u003cp\u003e\nSet to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ticks_per_frame\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::TicksPerFrame","doc":"\u003cp\u003e\nTicksPerFrame returns the ticks per frame.\n\u003c/p\u003e\n\u003cp\u003e\nFor some codecs, the time base is closer to the field rate than the frame rate.\n\u003c/p\u003e\n\u003cp\u003e\nMost notably, H.264 and MPEG-2 specify time_base as half of frame duration if no telecine is used ...\n\u003c/p\u003e\n\u003cp\u003e\nSet to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ticks_per_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_shrink_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::ShrinkSideData","doc":"\u003cp\u003e\nShrinkSideData shrinks the already allocated side data buffer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_shrink_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacketSideData::size","goRep":[{"name":"ffgopeg.v1/avcodec.PacketSideData::Size","doc":"\u003cp\u003e\nSize returns size of the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacketSideData::size\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::compression_level","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CompressionLevel","doc":"\u003cp\u003e\nCompressionLevel returns the compression level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::compression_level\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetCompressionLevel","doc":"\u003cp\u003e\nSetCompressionLevel sets the compression level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::compression_level\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slice_flags","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSliceFlags","doc":"\u003cp\u003e\nSetSliceFlags sets the slice flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_flags\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SliceFlags","doc":"\u003cp\u003e\nSliceFlags returns the slice flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::temporal_cplx_masking","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetTemporalCplxMasking","doc":"\u003cp\u003e\nSetTemporalCplxMasking returns the temporal complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::temporal_cplx_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::TemporalCplxMasking","doc":"\u003cp\u003e\nTemporalCplxMasking returns the temporal complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::temporal_cplx_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::chroma_location","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ChromaLocation","doc":"\u003cp\u003e\nChromaLocation returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::chroma_location\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_network_deinit","goRep":[{"name":"ffgopeg.v1/avformat.NetworkDeinit","doc":"\u003cp\u003e\nNetworkDeinit undoes the initialization done by avformat_network_init.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_network_deinit\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::dark_masking","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DarkMasking","doc":"\u003cp\u003e\nDarkMasking returns the darkness masking (0 means \u0026#34;disabled\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dark_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDarkMasking","doc":"\u003cp\u003e\nSetDarkMasking sets the darkness masking (0 means \u0026#34;disabled\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dark_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::CodecType","doc":"\u003cp\u003e\nCodecType returns the general type of the encoded data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_range","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ColorRange","doc":"\u003cp\u003e\nColorRange returns additional colorspace characteristics.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_close","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParserContext::Close","doc":"\u003cp\u003e\nClose closes the CodecParserContext.\nC-Function: av_parser_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_get_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::SideDataOfType","doc":"\u003cp\u003e\nSideDataOfType get side information from packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_set_auto_convert","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::SetAutoConvert","doc":"\u003cp\u003e\nSetAutoConvert enables or disables automatic format conversion inside the graph.\nflags can be any of the AVFILTER_AUTO_CONVERT_* constants.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_set_auto_convert\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_find_best_stream","goRep":[{"name":"ffgopeg.v1/avformat.FindBestStream","doc":"\u003cp\u003e\nFindBestStream finds the \u0026#34;best\u0026#34; stream in the file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_find_best_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_uncoded_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::WriteUncodedFrame","doc":"\u003cp\u003e\nWriteUncodedFrame writes an uncoded frame to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_uncoded_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::last_predictor_count","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::LastPredictorCount","doc":"\u003cp\u003e\nLastPredictorCount returns the amount of previous MV predictors (2a+1 x 2a+1)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::last_predictor_count\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetLastPredictorCount","doc":"\u003cp\u003e\nSetLastPredictorCount sets the amount of previous MV predictors (2a+1 x 2a+1)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::last_predictor_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::max_qdiff","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MaxQDiff","doc":"\u003cp\u003e\nMaxQDiff returns the maximum quantizer difference between frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_qdiff\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMaxQDiff","doc":"\u003cp\u003e\nSetMaxQDiff sets the maximum quantizer difference between frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_qdiff\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_safe_callbacks","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetThreadSafeCallbacks","doc":"\u003cp\u003e\nSetThreadSafeCallbacks sets whether or not the custom get_buffer() callback can be called synchronously from another threa, which allows faster multithreaded decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_safe_callbacks\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::ThreadSafeCallbacks","doc":"\u003cp\u003e\nThreadSafeCallbacks returns whether or not the custom get_buffer() callback can be called synchronously from another threa, which allows faster multithreaded decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_safe_callbacks\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::frame_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::FrameSize","doc":"\u003cp\u003e\nFrameSize returns the audio frame size, if known.\nRequired by some formats to be static.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::frame_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_convertPalette8ToPacked32","goRep":[{"name":"ffgopeg.v1/swscale.ConvertPalette8ToPacked32","doc":"\u003cp\u003e\nConvertPalette8ToPacked32 converts an 8-bit paletted frame into a frame with a color depth of 32 bits.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_convertPalette8ToPacked32\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Data","doc":"\u003cp\u003e\nData returns the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::side_data_elems","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::SideDataElems","doc":"\u003cp\u003e\nSideDataElems returns something undefined...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::side_data_elems\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_get_filter","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::Filter","doc":"\u003cp\u003e\nFilter retursn a filter instance identified by instance name from graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_get_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_insert_filter","goRep":[{"name":"ffgopeg.v1/avfilter.FilterLink::InsertFilter","doc":"\u003cp\u003e\nInsertFilter insterts a filter in the middle of an existing link.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_insert_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_seek_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SeekFrame","doc":"\u003cp\u003e\nSeekFrame seeks to the keyframe at timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_seek_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_ref","goRep":[{"name":"ffgopeg.v1/avutil.FrameRef","doc":"\u003cp\u003e\nFrameRef sets up a new reference to the data described by a given frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::err_recognition","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ErrRecognition","doc":"\u003cp\u003e\nErrRecognition returns the error recognition.\nIt may misdetect some more or less valid parts as errors.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::err_recognition\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetErrRecognition","doc":"\u003cp\u003e\nSetErrRecognition sets the error recognition.\nIt may misdetect some more or less valid parts as errors.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::err_recognition\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_cmp","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MeCmp","doc":"\u003cp\u003e\nMeCmp returns the motion estimation comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMeCmp","doc":"\u003cp\u003e\nSetMeCmp sets the motion estimation comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_min_vbv_overflow_use","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcMinVbvOverflowUse","doc":"\u003cp\u003e\nRcMinVbvOverflowUse returns the ratecontrol attempt to use, at least, times the amount needed to prevent a vbv overflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_vbv_overflow_use\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcMinVbvOverflowUse","doc":"\u003cp\u003e\nSetRcMinVbvOverflowUse sets the ratecontrol attempt to use, at least, times the amount needed to prevent a vbv overflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_vbv_overflow_use\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_receive_frame","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ReceiveFrame","doc":"\u003cp\u003e\nReceiveFrame receives a frame as output from the decoder.\nC-Function: avcodec_receive_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_exact_bits_per_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecId::ExactBitsPerSample","doc":"\u003cp\u003e\nExactBitsPerSample returns codec bits per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_exact_bits_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_grow_packet","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::GrowPacket","doc":"\u003cp\u003e\nGrowPacket increases packet size, correctly zeroing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_grow_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_match_ext","goRep":[{"name":"ffgopeg.v1/avformat.AvMatchExt","doc":"\u003cp\u003e\nint av_match_ext (const char *filename, const char *extensions)\nReturn a positive value if the given filename has one of the given extensions, 0 otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_match_ext\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_video_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SetVideoCodec","doc":"\u003cp\u003e\nSetVideoCodec sets the video codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_video_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::delay","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Delay","doc":"\u003cp\u003e\nDelay returns the codec delay.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Number of frames delay there will be from the encoder input to the decoder output. (we assume the decoder matches the spec) Decoding: Number of frames delay in addition to what a standard decoder as specified in the spec would produce.\n\u003c/p\u003e\n\u003cp\u003e\nVideo: Number of frames the decoded output will be delayed relative to the encoded input.\n\u003c/p\u003e\n\u003cp\u003e\nAudio: For encoding, this field is unused (see initial_padding).\n\u003c/p\u003e\n\u003cp\u003e\nFor decoding, this is the number of samples the decoder needs to output before the decoder\u0026#39;s output is valid. When seeking, you should start decoding this many samples prior to your desired seek point.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::delay\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetDelay","doc":"\u003cp\u003e\nSetDelay sets the codec delay.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Number of frames delay there will be from the encoder input to the decoder output. (we assume the decoder matches the spec) Decoding: Number of frames delay in addition to what a standard decoder as specified in the spec would produce.\n\u003c/p\u003e\n\u003cp\u003e\nVideo: Number of frames the decoded output will be delayed relative to the encoded input.\n\u003c/p\u003e\n\u003cp\u003e\nAudio: For encoding, this field is unused (see initial_padding).\n\u003c/p\u003e\n\u003cp\u003e\nFor decoding, this is the number of samples the decoder needs to output before the decoder\u0026#39;s output is valid. When seeking, you should start decoding this many samples prior to your desired seek point.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_free_context","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Free","doc":"\u003cp\u003e\nFree frees the codec context and everything associated with it.\nC-Function: avcodec_free_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::i_quant_factor","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IQuantFactor","doc":"\u003cp\u003e\nIQuantFactor returns the qscale factor between P- and I-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q * factor + offset).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_factor\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetIQuantFactor","doc":"\u003cp\u003e\nSetIQuantFactor sets the qscale factor between P- and I-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q * factor + offset).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_factor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_lmin","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MbLMin","doc":"\u003cp\u003e\nMbLMin returns the minimum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmin\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMbLMin","doc":"\u003cp\u003e\nSetMbLMin returns the minimum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmin\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_new_side_data","goRep":[{"name":"ffgopeg.v1/avutil.Frame::NewSideData","doc":"\u003cp\u003e\nNewSideData adds a new side data to a frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_new_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_index_search_timestamp","goRep":[{"name":"ffgopeg.v1/avformat.AvIndexSearchTimestamp","doc":"\u003cp\u003e\nGet the index for a specific timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_index_search_timestamp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_iformat_next","goRep":[{"name":"ffgopeg.v1/avformat.InputFormats","doc":"\u003cp\u003e\nInputFormats returns a channel which can be used to iterate over the input formats.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor in := range avformat.InputFormats() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_iformat_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_pkt_timebase","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::PktTimebase","doc":"\u003cp\u003e\nPktTimebase returns the packet timebase.\nC-Function: av_codec_get_pkt_timebase\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_min_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcMinRate","doc":"\u003cp\u003e\nRcMinRate returns the minimum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcMinRate","doc":"\u003cp\u003e\nSetRcMinRate sets the minimum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_codec_descriptor","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetCodecDescriptor","doc":"\u003cp\u003e\nSetCodecDescriptor sets the CodecDescriptor.\nC-Function: av_codec_set_codec_descriptor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bit_rate","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::BitRate","doc":"\u003cp\u003e\nBitRate returns the average bitrate of the encoded data (in bits per second).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bit_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::pts","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Pts","doc":"\u003cp\u003e\nPts returns the presentation timestamp in AVStream-\u0026gt;time_base units; the time at which the decompressed packet will be presented to the user.\n\u003c/p\u003e\n\u003cp\u003e\nCan be AV_NOPTS_VALUE if it is not stored in the file. pts MUST be larger or equal to dts as presentation cannot happen before decompression, unless one wants to view hex dumps. Some formats misuse the terms dts and pts/cts to mean something different. Such timestamps must be converted to true pts/dts before they are stored in AVPacket.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_display_rotation_get","goRep":[{"name":"ffgopeg.v1/avformat.Stream::GetRotation","doc":"\u003cp\u003e\nGetRotation does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_display_rotation_get\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_copy_props","goRep":[{"name":"ffgopeg.v1/avutil.CopyProps","doc":"\u003cp\u003e\nCopyProps copies only \u0026#34;metadata\u0026#34; fields from src to dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_copy_props\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedInput","goRep":[{"name":"ffgopeg.v1/swscale.IsSupportedInput","doc":"\u003cp\u003e\nIsSupportedInput returns true if pix_fmt is a supported input format,false otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedInput\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_chroma_intra_matrix","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ChromaIntraMatrix","doc":"\u003cp\u003e\nChromaIntraMatrix returns something undocumented.\nC-Function: av_codec_get_chroma_intra_matrix\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetChromaIntraMatrix","doc":"\u003cp\u003e\nSetChromaIntraMatrix sets something undocumented.\nC-Function: av_codec_get_chroma_intra_matrix\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::codec_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CodecType","doc":"\u003cp\u003e\nCodecType return the codec type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::codec_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::height","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Height","doc":"\u003cp\u003e\nHeight returns the raw image height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::height\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::trailing_padding","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::TrailingPadding","doc":"\u003cp\u003e\nTrailingPadding returns the amount of padding (in samples) appended by the encoder to the end of the audio. I.e. this number of decoded samples must be discarded by the caller from the end of the stream to get the original audio without any trailing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::trailing_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::cutoff","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Cutoff","doc":"\u003cp\u003e\nCutoff returns the audio cutoff bandwidth (0 means \u0026#34;automatic\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::cutoff\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetCutoff","doc":"\u003cp\u003e\nSetCutoff sets the audio cutoff bandwidth (0 means \u0026#34;automatic\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::cutoff\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::extradata_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ExtradataSize","doc":"\u003cp\u003e\nExtradataSize returns the extradata size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::extradata_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_bottom","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSkipBottom","doc":"\u003cp\u003e\nSetSkipBottom sets the number of macroblocks rows at the bottom which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_bottom\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SkipBottom","doc":"\u003cp\u003e\nSkipBottom returns the number of macroblocks rows at the bottom which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_bottom\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_bits_per_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecId::BitsPerSample","doc":"\u003cp\u003e\nBitsPerSample returns codec bits per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bits_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::channels","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Channels","doc":"\u003cp\u003e\nChannels return the number of audio channels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::channels\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::stream_index","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::StreamIndex","doc":"\u003cp\u003e\nStreamIndex returns the index of the stream this packet originated from.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::stream_index\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_output_format","goRep":[{"name":"ffgopeg.v1/avformat.OutputFormat::Register","doc":"\u003cp\u003e\nRegister registers the OutputFormat.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_output_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::b_quant_factor","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BQuantFactor","doc":"\u003cp\u003e\nBQuantFactor returns the qscale factor between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_factor\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBQuantFactor","doc":"\u003cp\u003e\nSetBQuantFactor sets the qscale factor between IP and B-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q*factor+offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q*factor+offset)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_factor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bit_rate_tolerance","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BitRateTolerance","doc":"\u003cp\u003e\nBitRateTolerance returns the number of bits the bitstream is allowed to diverge from the reference.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate_tolerance\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetBitRateTolerance","doc":"\u003cp\u003e\nSetBitRateTolerance sets the number of bits the bitstream is allowed to diverge from the reference.\nThe reference can be CBR (for CBR pass 1) or VBR (for VBR pass 2)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate_tolerance\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_encode_subtitle","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::EncodeSubtitle","doc":"\u003cp\u003e\nEncodeSubtitle encodes a subtitle message.\nC-Function: avcodec_encode_subtitle\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::level","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Level","doc":"\u003cp\u003e\nLevel returns the level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::level\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetLevel","doc":"\u003cp\u003e\nSetLevel sets the level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::level\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_configuration","goRep":[{"name":"ffgopeg.v1/avutil.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavutil build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::buf","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Buf","doc":"\u003cp\u003e\nBuf returns a reference to the reference-counted buffer where the packet data is stored.\nMay be nil, then the packet data is not reference-counted.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::buf\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_oformat_next","goRep":[{"name":"ffgopeg.v1/avformat.OutputFormats","doc":"\u003cp\u003e\nOutputFormats returns a channel which can be used to iterate over the output formats.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor out := range avformat.OutputFormats() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_oformat_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_int_list_length_for_size","goRep":[{"name":"ffgopeg.v1/avutil.IntListLengthForSize","doc":"\u003cp\u003e\nIntListLengthForSize computes the length of an integer list.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_int_list_length_for_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_setColorspaceDetails","goRep":[{"name":"ffgopeg.v1/swscale.Context::SetColorspaceDetails","doc":"\u003cp\u003e\nSetColorspaceDetails sets the colorspace details.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_setColorspaceDetails\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::has_b_frames","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::HasBFrames","doc":"\u003cp\u003e\nHasBFrames returns the size of the reordering buffer in the decoder.\n\u003c/p\u003e\n\u003cp\u003e\nFor MPEG-2 it is 1 IPB or 0 low delay IP.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::has_b_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::i_quant_offset","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IQuantOffset","doc":"\u003cp\u003e\nIQuantOffset returns the qscale offset between P and I-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetIQuantOffset","doc":"\u003cp\u003e\nSetIQuantOffset sets the qscale offset between P and I-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_receive_packet","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ReceivePacket","doc":"\u003cp\u003e\nReceivePacket receives a packet as output from the decoder.\nC-Function: avcodec_receive_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::video_delay","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::VideoDelay","doc":"\u003cp\u003e\nVideoDelay returns the number of delayed frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::video_delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_dump_format","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::DumpFormat","doc":"\u003cp\u003e\nDumpFormat prints detailed information about the input or output format, such as duration, bitrate, streams, container, programs, metadata, side data, codec and time base.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dump_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_convert_frame","goRep":[{"name":"ffgopeg.v1/swresample.Context::ConvertFrame","doc":"\u003cp\u003e\nConvertFrame converts the samples in the input Frame and write them to the output Frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_convert_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_scaleVec","goRep":[{"name":"ffgopeg.v1/swscale.Vector::Scale","doc":"\u003cp\u003e\nScale scales all the coefficients of a by the scalar value.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_scaleVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_audio_frame_duration","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::AudioFrameDuration","doc":"\u003cp\u003e\nAudioFrameDuration returns audio frame duration, or 0 if not able to determine.\nC-Function: av_get_audio_frame_duration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_close","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Close","doc":"\u003cp\u003e\nClose closes a given Context and free all the data associated with it (but not the Context itself).\nC-Function: avcodec_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_default_get_format","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DefaultGetFormat","doc":"\u003cp\u003e\nDefaultGetFormat is undocumented...\nC-Function: avcodec_default_get_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qcompress","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::QCompress","doc":"\u003cp\u003e\nQCompress returns the amount of qscale change between easy \u0026amp; hard scenes. (0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qcompress\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetQCompress","doc":"\u003cp\u003e\nSetQCompress sets the amount of qscale change between easy \u0026amp; hard scenes. (0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qcompress\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_split_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::SplitSideData","doc":"\u003cp\u003e\nSplitSideData does something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_split_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_capabilities_create","goRep":[{"name":"ffgopeg.v1/avdevice.CapabilitiesCreate","doc":"\u003cp\u003e\nCapabilitiesCreate initializes capabilities probing API based on AvOption API.\n\u003c/p\u003e\n\u003cp\u003e\nCapabilitiesFree() must be called when query capabilities API is not used anymore.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_capabilities_create\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_uncoded_frame_query","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::WriteUncodedFrameQuery","doc":"\u003cp\u003e\nWriteUncodedFrameQuery tests whether a muxer supports uncoded frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_uncoded_frame_query\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_alloc_set_opts","goRep":[{"name":"ffgopeg.v1/swresample.Context::SetOpts","doc":"\u003cp\u003e\nSetOpts allocates Context if needed and set/reset common parameters.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_alloc_set_opts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::field_order","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::FieldOrder","doc":"\u003cp\u003e\nFieldOrder returns the field order.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::field_order\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetFieldOrder","doc":"\u003cp\u003e\nSetFieldOrder sets the field order.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::field_order\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_buffer_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::RcBufferSize","doc":"\u003cp\u003e\nRcBufferSize returns the decoder bitstream buffer size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_buffer_size\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetRcBufferSize","doc":"\u003cp\u003e\nSetRcBufferSize sets the decoder bitstream buffer size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_buffer_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_free_context","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::Free","doc":"\u003cp\u003e\nFree frees the Context and all its streams.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_free_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_next_pts","goRep":[{"name":"ffgopeg.v1/swresample.Context::NextPts","doc":"\u003cp\u003e\nNextPts converts the next timestamp from input to output timestamps are in 1/(in_sample_rate * out_sample_rate) units.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_next_pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::workaround_bugs","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetWorkaroundBugs","doc":"\u003cp\u003e\nSetWorkaroundBugs sets which bufs to work around.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::workaround_bugs\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::WorkaroundBugs","doc":"\u003cp\u003e\nWorkaroundBugs returns which bufs to work around.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::workaround_bugs\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::height","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Height","doc":"\u003cp\u003e\nHeight returns the height of the video frame in pixels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::height\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_getCoefficients","goRep":[{"name":"ffgopeg.v1/swscale.Coefficients","doc":"\u003cp\u003e\nCoefficients returns a pointer to yuv\u0026lt;-\u0026gt;rgb coefficients for the given colorspace suitable for sws_setColorspaceDetails().\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_getCoefficients\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_version","goRep":[{"name":"ffgopeg.v1/avutil.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVUTIL_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_descriptor_get","goRep":[{"name":"ffgopeg.v1/avcodec.CodecId::Descriptor","doc":"\u003cp\u003e\nDescriptor returns the CodecDescriptor of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_descriptor_get\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_free","goRep":[{"name":"ffgopeg.v1/avfilter.FilterContext::Free","doc":"\u003cp\u003e\nFree frees a filter context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_filename_number_test","goRep":[{"name":"ffgopeg.v1/avformat.AvFilenameNumberTest","doc":"\u003cp\u003e\nCheck whether filename actually is a numbered sequence generator.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_filename_number_test\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_guess_sample_aspect_ratio","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::GuessSampleAspectRatio","doc":"\u003cp\u003e\nGuessSampleAspectRatio guesses the sample aspect ratio of a frame, based on both the stream and the frame aspect ratio.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_guess_sample_aspect_ratio\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_audio_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SetAudioCodec","doc":"\u003cp\u003e\nSetAudioCodec sets the audio codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_audio_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_packet","goRep":[{"name":"ffgopeg.v1/avformat.IOContext::GetPacket","doc":"\u003cp\u003e\nGetPacket allocates and reads the payload of a packet and initialize its fields with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_parser","goRep":[{"name":"ffgopeg.v1/avformat.Stream::StreamGetParser","doc":"\u003cp\u003e\nStreamGetParser does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_parser\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_qp_table","goRep":[{"name":"ffgopeg.v1/avutil.Frame::QpTable","doc":"\u003cp\u003e\nQpTable returns the qp table.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_qp_table\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::pre_dia_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::PreDiaSize","doc":"\u003cp\u003e\nPreDiaSize returns the ME prepass diamond size \u0026amp; shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pre_dia_size\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetPreDiaSize","doc":"\u003cp\u003e\nSetPreDiaSize sets the ME prepass diamond size \u0026amp; shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pre_dia_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::width","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetWidth","doc":"\u003cp\u003e\nSetWidth sets the raw image width.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::width\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::Width","doc":"\u003cp\u003e\nWidth returns the raw image width.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::width\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_get_type","goRep":[{"name":"ffgopeg.v1/avfilter.FilterPad::Type","doc":"\u003cp\u003e\nType returns the type of an FilterPad.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_get_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_find_program_from_stream","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::IterateProgramsFromStream","doc":"\u003cp\u003e\nIterateProgramsFromStream returns a channel which can be used to iterate over the Programs from the given Stream.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor i, prog := range fmtCtxt.IterateProgramsFromStream(0) {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_find_program_from_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeContext","goRep":[{"name":"ffgopeg.v1/swscale.Context::Free","doc":"\u003cp\u003e\nFree frees the swscaler context swsContext.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeContext\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::seek_preroll","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::SeekPreroll","doc":"\u003cp\u003e\nSeekPreroll returns the number of sample to skip after a discontinuity.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_new_side_data","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::NewSideData","doc":"\u003cp\u003e\nNewSideData allocates new information of a packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_new_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_capabilities_free","goRep":[{"name":"ffgopeg.v1/avdevice.CapabilitiesFree","doc":"\u003cp\u003e\nCapabilitiesFree frees resources created by CapabilitiesCreate()\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_capabilities_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse2","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::Parse2","doc":"\u003cp\u003e\nParse2 adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse2\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_enum_to_chroma_pos","goRep":[{"name":"ffgopeg.v1/avcodec.ChromaLocation::ToChromaPos","doc":"\u003cp\u003e\nToChromaPos converts the ChromaLocation to swscale x/y chroma position.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_enum_to_chroma_pos\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_is_decoder","goRep":[{"name":"ffgopeg.v1/avcodec.Codec::IsDecoder","doc":"\u003cp\u003e\nIsDecoder returns true if the codec is an decoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_is_decoder\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::flags2","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::Flags2","doc":"\u003cp\u003e\nFlags2 returns the flags AV_CODEC_FLAG2_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags2\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetFlags2","doc":"\u003cp\u003e\nSetFlags2 sets the flags AV_CODEC_FLAG2_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_cmp","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MbCmp","doc":"\u003cp\u003e\nMbCmp returns the macroblock comparison function.\n(not supported yet)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMbCmp","doc":"\u003cp\u003e\nSetMbCmp sets the macroblock comparison function.\n(not supported yet)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_convertPalette8ToPacked24","goRep":[{"name":"ffgopeg.v1/swscale.ConvertPalette8ToPacked24","doc":"\u003cp\u003e\nConvertPalette8ToPacked24 converts an 8-bit paletted frame into a frame with a color depth of 24 bits.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_convertPalette8ToPacked24\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_next","goRep":[{"name":"ffgopeg.v1/avfilter.Filters","doc":"\u003cp\u003e\nFilters returns a channel which can be used to iterate over the filters.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor f := range avdevice.Filters() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: avfilter_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_find_stream_info","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::FindStreamInfo","doc":"\u003cp\u003e\nFindStreamInfo reads packets of a media file to get stream information.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_find_stream_info\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_new_program","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::NewProgram","doc":"\u003cp\u003e\nNewProgram creates a new Program.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_new_program\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_codec_tag_string","goRep":[{"name":"ffgopeg.v1/avcodec.GetCodecTagString","doc":"\u003cp\u003e\nGetCodecTagString returns a string representing the codec tag codec_tag.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_codec_tag_string\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::subtitle_header_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SubtitleHeaderSize","doc":"\u003cp\u003e\nSubtitleHeaderSize returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::subtitle_header_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecId::Type","doc":"\u003cp\u003e\nType returns the type of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::flags","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Flags","doc":"\u003cp\u003e\nFlags returns a combination of AV_PKT_FLAG values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_strerror","goRep":[{"name":"ffgopeg.v1/avutil.Strerror","doc":"\u003cp\u003e\nStrerror returns a descriptive string of the given return code.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_strerror\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_max_lowres","goRep":[{"name":"ffgopeg.v1/avcodec.Codec::MaxLowres","doc":"\u003cp\u003e\nMaxLowres returns the maximum lowres supported by the decoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_max_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::block_align","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::BlockAlign","doc":"\u003cp\u003e\nBlockAlign returns the number of bytes per packet if constant and known or 0.\nUsed by some WAV based audio codecs.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::block_align\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::duration","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Duration","doc":"\u003cp\u003e\nDuration returns the duration of this packet in AVStream-\u0026gt;time_base units, 0 if unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::duration\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_picture_type_char","goRep":[{"name":"ffgopeg.v1/avutil.PictureTypeChar","doc":"\u003cp\u003e\nPictureTypeChar returns a single letter to describe the given picture type pict_type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_picture_type_char\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_drop_output","goRep":[{"name":"ffgopeg.v1/swresample.Context::DropOutput","doc":"\u003cp\u003e\nDropOutput drops the specified number of output samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_drop_output\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_frame","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSkipFrame","doc":"\u003cp\u003e\nSetSkipFrame sets the skip decoding for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_frame\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SkipFrame","doc":"\u003cp\u003e\nSkipFrame returns the skip decoding for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_link_free","goRep":[{"name":"ffgopeg.v1/avfilter.FilterLink::Free","doc":"\u003cp\u003e\nFree the link in *link, and set its pointer to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_link_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_metadata_header_padding","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::MetadataHeaderPadding","doc":"\u003cp\u003e\nMetadataHeaderPadding returns metadata header padding size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_metadata_header_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_side_data","goRep":[{"name":"ffgopeg.v1/avformat.Stream::SideData","doc":"\u003cp\u003e\nSideData returns side information from stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_compensation","goRep":[{"name":"ffgopeg.v1/swresample.Context::SetCompensation","doc":"\u003cp\u003e\nSetCompensation activates resampling compensation (\u0026#34;soft\u0026#34; compensation).\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_compensation\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::spatial_cplx_masking","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSpatialCplxMasking","doc":"\u003cp\u003e\nSetSpatialCplxMasking sets the spatial complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::spatial_cplx_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SpatialCplxMasking","doc":"\u003cp\u003e\nSpatialCplxMasking returns the spatial complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::spatial_cplx_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_fmt_ctx_get_duration_estimation_method","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::DurationEstimationMethod","doc":"\u003cp\u003e\nDurationEstimationMethod returns the method used to set ctx-\u0026gt;duration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_fmt_ctx_get_duration_estimation_method\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_video_codec","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::VideoCodec","doc":"\u003cp\u003e\nVideoCodec returns the VideoCodec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_video_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_write_header","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::WriteHeader","doc":"\u003cp\u003e\nWriteHeader allocates the stream private data and write the stream header to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_write_header\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_align_dimensions2","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::AlignDimensions2","doc":"\u003cp\u003e\nAlignDimensions2 modifies width and height values so that they will result in a memory buffer that is acceptable for the codec if you also ensure that all line sizes are a multiple of the respective linesize_align[i].\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\nC-Function: avcodec_align_dimensions2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_loop_filter","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetSkipLoopFilter","doc":"\u003cp\u003e\nSetSkipLoopFilter sets the skip loop filtering for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_loop_filter\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SkipLoopFilter","doc":"\u003cp\u003e\nSkipLoopFilter returns the skip loop filtering for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_loop_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_register_all","goRep":[{"name":"ffgopeg.v1/avfilter.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes the filter system.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_inout_free","goRep":[{"name":"ffgopeg.v1/avfilter.FilterInOut::Free","doc":"\u003cp\u003e\nFree frees the supplied list of FilterInOut and set *inout to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_inout_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::channel_layout","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::ChannelLayout","doc":"\u003cp\u003e\nChannelLayout returns the channel layout bitmask.\nMay be 0 if the channel layout is unknown or unspecified, otherwise the number of bits set bmust be equal to the channels field.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::channel_layout\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::level","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Level","doc":"\u003cp\u003e\nLevel returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::level\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::dts","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::Dts","doc":"\u003cp\u003e\nDts returns the decompression timestamp in AVStream-\u0026gt;time_base units; the time at which the packet is decompressed.\nCan be AV_NOPTS_VALUE if it is not stored in the file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::dts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::p_masking","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::PMasking","doc":"\u003cp\u003e\nPMasking returns the spatial complexity masking. 0 equals disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::p_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetPMasking","doc":"\u003cp\u003e\nSetPMasking sets the spatial complexity masking. 0 equals disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::p_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_config_frame","goRep":[{"name":"ffgopeg.v1/swresample.Context::ConfigFrame","doc":"\u003cp\u003e\nConfigFrame configures or reconfigures the Context using the information provided by the AvFrames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_config_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_init_context","goRep":[{"name":"ffgopeg.v1/swscale.Context::Init","doc":"\u003cp\u003e\nInit initializes the swscaler context sws_context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_init_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::log_level_offset","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::LogLevelOffset","doc":"\u003cp\u003e\nLogLevelOffset returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::log_level_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetLogLevelOffset","doc":"\u003cp\u003e\nSetLogLevelOffset sets something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::log_level_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_license","goRep":[{"name":"ffgopeg.v1/avfilter.License","doc":"\u003cp\u003e\nLicense returns the libavfilter license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_get_name","goRep":[{"name":"ffgopeg.v1/avfilter.FilterPad::Name","doc":"\u003cp\u003e\nName returns the name of a FilterPad.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_get_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_url_split","goRep":[{"name":"ffgopeg.v1/avformat.AvUrlSplit","doc":"\u003cp\u003e\nSplit a URL string into components.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_url_split\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_unref","goRep":[{"name":"ffgopeg.v1/avutil.Frame::Unref","doc":"\u003cp\u003e\nUnref unreferences all the buffers referenced by frame and reset the frame fields.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_unref\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_license","goRep":[{"name":"ffgopeg.v1/avcodec.License","doc":"\u003cp\u003e\nLicense returns the libavcodec license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_range","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ColorRange","doc":"\u003cp\u003e\nColorRange returns the MPEG vs JPEG YUV range.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_range\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetColorRange","doc":"\u003cp\u003e\nSetColorRange sets the MPEG vs JPEG YUV range.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::frame_size","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::FrameSize","doc":"\u003cp\u003e\nFrameSize returns the number of samples per channel in an audio frame.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Set by libavcodec in avcodec_open2(). Each submitted frame except the last must contain exactly frame_size samples per channel. May be 0 when the codec has AV_CODEC_CAP_VARIABLE_FRAME_SIZE set, then the frame size is not restricted.\nDecoding: May be set by some decoders to indicate constant frame size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::frame_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_output_video_device_next","goRep":[{"name":"ffgopeg.v1/avdevice.OutputVideoDevices","doc":"\u003cp\u003e\nOutputVideoDevices returns a channel which can be used to iterate over the output video devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.OutputVideoDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_output_video_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_play","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::ReadPlay","doc":"\u003cp\u003e\nReadPlay starts playing a network-based stream (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_play\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_metadata_header_padding","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::SetMetadataHeaderPadding","doc":"\u003cp\u003e\nSetMetadataHeaderPadding sets metadata header padding size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_metadata_header_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_append_packet","goRep":[{"name":"ffgopeg.v1/avformat.IOContext::AvAppendPacket","doc":"\u003cp\u003e\nRead data and append it to the current content of the Packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_append_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::frame_number","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::FrameNumber","doc":"\u003cp\u003e\nFrameNumber returns the Frame counter, set by libavcodec.\n\u003c/p\u003e\n\u003cp\u003e\nDecoding: Total number of frames returned from the decoder so far.\nEncoding: Total number of frames passed to the encoder so far.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::frame_number\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_subpel_quality","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::MeSubpelQuality","doc":"\u003cp\u003e\nMeSubpelQuality returns the subpel ME quality.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_subpel_quality\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetMeSubpelQuality","doc":"\u003cp\u003e\nSetMeSubpelQuality sets the subpel ME quality.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_subpel_quality\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::format","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::Format","doc":"\u003cp\u003e\nFormat returns the pixel/sample format of video/audio data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::format\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_dev_to_app_control_message","goRep":[{"name":"ffgopeg.v1/avdevice.DevToAppControlMessage","doc":"\u003cp\u003e\nDevToAppControlMessage sends control message from device to application.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_dev_to_app_control_message\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_dump","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::Dump","doc":"\u003cp\u003e\nDump dumps a graph into a human-readable string representation.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_dump\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_tag2","goRep":[{"name":"ffgopeg.v1/avformat.AvCodecGetTag2","doc":"\u003cp\u003e\nGet the codec tag for the given codec id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_tag2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_frame","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::ReadFrame","doc":"\u003cp\u003e\nReadFrame returns the next frame of a stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_trailer","goRep":[{"name":"ffgopeg.v1/avformat.FormatContext::WriteTrailer","doc":"\u003cp\u003e\nWriteTrailer writes the stream trailer to an output media file and free the file private data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_trailer\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_type","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetThreadType","doc":"\u003cp\u003e\nSetThreadType sets which multithreading methods to use.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_type\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::ThreadType","doc":"\u003cp\u003e\nThreadType returns which multithreading methods to use.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_tag","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::CodecTag","doc":"\u003cp\u003e\nCodecTag returns additional information about the codec (corrensponds to the AVI FOURCC).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_tag\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_pack_dictionary","goRep":[{"name":"ffgopeg.v1/avcodec.Dictionary::Pack","doc":"\u003cp\u003e\nPack packs the dictionary for use in side_data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_pack_dictionary\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_free_list_devices","goRep":[{"name":"ffgopeg.v1/avdevice.DeviceInfoList::Free","doc":"\u003cp\u003e\nFree is a convenient function to free result of ListDevices().\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_free_list_devices\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_free","goRep":[{"name":"ffgopeg.v1/avutil.Frame::Free","doc":"\u003cp\u003e\nFree frees the frame and any dynamically allocated objects in it, e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_is_open","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::IsOpen","doc":"\u003cp\u003e\nIsOpen returns true iff the CodecContext was opened and not yet closed.\nC-Function: avcodec_is_open\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::trellis","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::SetTrellis","doc":"\u003cp\u003e\nSetTrellis sets the trellis RD quantization.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::trellis\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::Trellis","doc":"\u003cp\u003e\nTrellis returns the trellis RD quantization.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::trellis\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_name","goRep":[{"name":"ffgopeg.v1/avcodec.CodecId::Name","doc":"\u003cp\u003e\nName returns the name of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bits_per_coded_sample","goRep":[{"name":"ffgopeg.v1/avcodec.CodecParameters::BitsPerCodedSample","doc":"\u003cp\u003e\nBitsPerCodedSample returns the number of bits per sample in the coded words.\n\u003c/p\u003e\n\u003cp\u003e\nThis is basically the bitrate per sample. It is mandatory for a bunch of formats to actually decode them. It\u0026#39;s the number of bits for one sample.\n\u003c/p\u003e\n\u003cp\u003e\nThis could be for example 4 for ADPCM For PCM formats this matches bits_per_raw_sample. Can be 0\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bits_per_coded_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_codec_descriptor","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::CodecDescriptor","doc":"\u003cp\u003e\nCodecDescriptor returns the CodecDescriptor.\nC-Function: av_codec_get_codec_descriptor\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_decode_subtitle2","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::DecodeSubtitle","doc":"\u003cp\u003e\nDecodeSubtitle decodes a subtitle message.\n\u003c/p\u003e\n\u003cp\u003e\nReturn a negative value on error, otherwise return the number of bytes used. If no subtitle could be decompressed, got_sub_ptr is zero. Otherwise, the subtitle is stored in *sub. Note that AV_CODEC_CAP_DR1 is not available for subtitle codecs. This is for simplicity, because the performance difference is expect to be negligible and reusing a get_buffer written for video codecs would probably perform badly due to a potentially very different allocation pattern.\n\u003c/p\u003e\n\u003cp\u003e\nSome decoders (those marked with CODEC_CAP_DELAY) have a delay between input and output. This means that for some packets they will not immediately produce decoded output and need to be flushed at the end of decoding to get all the decoded data. Flushing is done by calling this function with packets with avpkt-\u0026gt;data set to NULL and avpkt-\u0026gt;size set to 0 until it stops returning subtitles. It is safe to flush even those decoders that are not marked with CODEC_CAP_DELAY, then no subtitles will be returned.\nC-Function: avcodec_decode_subtitle2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::error_concealment","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::ErrorConcealment","doc":"\u003cp\u003e\nErrorConcealment returns error concealment flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::error_concealment\n\u003c/p\u003e\n"},{"name":"ffgopeg.v1/avcodec.CodecContext::SetErrorConcealment","doc":"\u003cp\u003e\nSetErrorConcealment sets error concealment flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::error_concealment\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_flush_buffers","goRep":[{"name":"ffgopeg.v1/avcodec.CodecContext::FlushBuffers","doc":"\u003cp\u003e\nFlushBuffers resets the internal decoder state / flush internal buffers.\nShould be called e.g. when seeking or when switching to a different stream.\nC-Function: avcodec_flush_buffers\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_shrink_packet","goRep":[{"name":"ffgopeg.v1/avcodec.Packet::ShrinkPacket","doc":"\u003cp\u003e\nShrinkPacket reduces packet size, correctly zeroing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_shrink_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_queue_command","goRep":[{"name":"ffgopeg.v1/avfilter.FilterGraph::QueueCommand","doc":"\u003cp\u003e\nQueueCommand queues a command for one or more filter instances.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_queue_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_add_index_entry","goRep":[{"name":"ffgopeg.v1/avformat.AvAddIndexEntry","doc":"\u003cp\u003e\nAdd an index entry into a sorted list.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_add_index_entry\n\u003c/p\u003e\n"}]}];
