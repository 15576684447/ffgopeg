DATA = [{"ffmpeg":"av_find_best_stream","goRep":[{"name":"ffgopeg/avformat.FindBestStream","doc":"\u003cp\u003e\nFindBestStream finds the \u0026#34;best\u0026#34; stream in the file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_find_best_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_setColorspaceDetails","goRep":[{"name":"ffgopeg/swscale.Context::SetColorspaceDetails","doc":"\u003cp\u003e\nSetColorspaceDetails sets the colorspace details.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_setColorspaceDetails\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::duration","goRep":[{"name":"ffgopeg/avcodec.Packet::Duration","doc":"\u003cp\u003e\nDuration returns the duration of this packet in AVStream-\u0026gt;time_base units, 0 if unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::duration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_dev_to_app_control_message","goRep":[{"name":"ffgopeg/avdevice.DevToAppControlMessage","doc":"\u003cp\u003e\nDevToAppControlMessage sends control message from device to application.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_dev_to_app_control_message\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_count","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetThreadCount","doc":"\u003cp\u003e\nSetThreadCount sets the thread count, which is used to decide how many independent tasks should be passed to execute().\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_count\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::ThreadCount","doc":"\u003cp\u003e\nThreadCount returns the thread count, which is used to decide how many independent tasks should be passed to execute().\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::colorspace","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Colorspace","doc":"\u003cp\u003e\nColorspace returns the YUV colorspace type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::colorspace\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetColorspace","doc":"\u003cp\u003e\nSetColorspace sets the YUV colorspace type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::colorspace\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_initial_buffer_occupancy","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcInitialBufferOccupancy","doc":"\u003cp\u003e\nRcInitialBufferOccupancy returns the number of bits which should be loaded into the rx buffer before decoding starts.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_initial_buffer_occupancy\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcInitialBufferOccupancy","doc":"\u003cp\u003e\nSetRcInitialBufferOccupancy sets the number of bits which should be loaded into the rx buffer before decoding starts.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_initial_buffer_occupancy\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slice_count","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSliceCount","doc":"\u003cp\u003e\nSetSliceCount sets the slice count.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_count\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SliceCount","doc":"\u003cp\u003e\nSliceCount returns the slice count.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_add_index_entry","goRep":[{"name":"ffgopeg/avformat.AvAddIndexEntry","doc":"\u003cp\u003e\nAdd an index entry into a sorted list.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_add_index_entry\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_find_program_from_stream","goRep":[{"name":"ffgopeg/avformat.FormatContext::IterateProgramsFromStream","doc":"\u003cp\u003e\nIterateProgramsFromStream returns a channel which can be used to iterate over the Programs from the given Stream.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor i, prog := range fmtCtxt.IterateProgramsFromStream(0) {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_find_program_from_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_input_format","goRep":[{"name":"ffgopeg/avformat.InputFormat::Register","doc":"\u003cp\u003e\nRegister registers the InputFormat.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_input_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::ildct_cmp","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IldctCmp","doc":"\u003cp\u003e\nIldctCmp returns the interlaced DCT comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ildct_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetIldctCmp","doc":"\u003cp\u003e\nSetIldctCmp sets the interlaced DCT comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ildct_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qmin","goRep":[{"name":"ffgopeg/avcodec.CodecContext::QMin","doc":"\u003cp\u003e\nQMin returns the minimum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmin\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetQMin","doc":"\u003cp\u003e\nSetQMin sets the minimum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmin\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_dump_format","goRep":[{"name":"ffgopeg/avformat.FormatContext::DumpFormat","doc":"\u003cp\u003e\nDumpFormat prints detailed information about the input or output format, such as duration, bitrate, streams, container, programs, metadata, side data, codec and time base.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dump_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_qp_table","goRep":[{"name":"ffgopeg/avutil.Frame::QpTable","doc":"\u003cp\u003e\nQpTable returns the qp table.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_qp_table\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slices","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSlices","doc":"\u003cp\u003e\nSetSlices sets the number of slices.\n\u003c/p\u003e\n\u003cp\u003e\nIndicates number of picture subdicisions. Used for parallelized decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slices\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::Slices","doc":"\u003cp\u003e\nSlices returns the number of slices.\n\u003c/p\u003e\n\u003cp\u003e\nIndicates number of picture subdicisions. Used for parallelized decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slices\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::subtitle_header_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SubtitleHeaderSize","doc":"\u003cp\u003e\nSubtitleHeaderSize returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::subtitle_header_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_match_ext","goRep":[{"name":"ffgopeg/avformat.AvMatchExt","doc":"\u003cp\u003e\nint av_match_ext (const char *filename, const char *extensions)\nReturn a positive value if the given filename has one of the given extensions, 0 otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_match_ext\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_oformat_next","goRep":[{"name":"ffgopeg/avformat.OutputFormats","doc":"\u003cp\u003e\nOutputFormats returns a channel which can be used to iterate over the output formats.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor out := range avformat.OutputFormats() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_oformat_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_all","goRep":[{"name":"ffgopeg/avformat.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes libavformat and register all the muxers, demuxers and protocols.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_override_count","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcOverrideCount","doc":"\u003cp\u003e\nRcOverrideCount returns ratecontrol override, see RcOverride.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_override_count\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcOverrideCount","doc":"\u003cp\u003e\nSetRcOverrideCount sets ratecontrol override, see RcOverride.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_override_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::spatial_cplx_masking","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSpatialCplxMasking","doc":"\u003cp\u003e\nSetSpatialCplxMasking sets the spatial complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::spatial_cplx_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SpatialCplxMasking","doc":"\u003cp\u003e\nSpatialCplxMasking returns the spatial complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::spatial_cplx_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::debug","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Debug","doc":"\u003cp\u003e\nDebug returns... the documentation only says \u0026#34;debug\u0026#34;\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDebug","doc":"\u003cp\u003e\nSetDebug sets... the documentation only says \u0026#34;debug\u0026#34;\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::debug_mv","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DebugMv","doc":"\u003cp\u003e\nDebugMv returns... the documentation only says \u0026#34;debug\u0026#34;\nCode outside libavcodec should access this field using AVOptions.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug_mv\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDebugMv","doc":"\u003cp\u003e\nSetDebugMv sets... the documentation only says \u0026#34;debug\u0026#34;\nCode outside libavcodec should access this field using AVOptions.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::debug_mv\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_min_vbv_overflow_use","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcMinVbvOverflowUse","doc":"\u003cp\u003e\nRcMinVbvOverflowUse returns the ratecontrol attempt to use, at least, times the amount needed to prevent a vbv overflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_vbv_overflow_use\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcMinVbvOverflowUse","doc":"\u003cp\u003e\nSetRcMinVbvOverflowUse sets the ratecontrol attempt to use, at least, times the amount needed to prevent a vbv overflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_vbv_overflow_use\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::pos","goRep":[{"name":"ffgopeg/avcodec.Packet::Pos","doc":"\u003cp\u003e\nPos returns the byte position in stream, -1 if unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::pos\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_dump","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::Dump","doc":"\u003cp\u003e\nDump dumps a graph into a human-readable string representation.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_dump\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_seek_file","goRep":[{"name":"ffgopeg/avformat.FormatContext::SeekFile","doc":"\u003cp\u003e\nSeekFile seeks to timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_seek_file\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bidir_refine","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BidirRefine","doc":"\u003cp\u003e\nBidirRefine returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bidir_refine\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBidirRefine","doc":"\u003cp\u003e\nSetBidirRefine sets something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bidir_refine\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_primaries","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ColorPrimaries","doc":"\u003cp\u003e\nColorPrimaries returns the chromaticity coordinates of the source primaries.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_primaries\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetColorPrimaries","doc":"\u003cp\u003e\nSetColorPrimaries sets the chromaticity coordinates of the source primaries.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_primaries\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_planar_sample_fmt","goRep":[{"name":"ffgopeg/avutil.SampleFormat::Planar","doc":"\u003cp\u003e\nPlanar returns the planar variant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_planar_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"GoString","goRep":[{"name":"ffgopeg/swscale.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libswscale build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: GoString\n\u003c/p\u003e\n"},{"name":"ffgopeg/swscale.License","doc":"\u003cp\u003e\nLicense returns the libswscale license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: GoString\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_primaries","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ColorPrimaries","doc":"\u003cp\u003e\nColorPrimaries returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_primaries\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_from_data","goRep":[{"name":"ffgopeg/avcodec.Packet::PacketFromData","doc":"\u003cp\u003e\nPacketFromData initializes a reference-counted packet from av_malloc()ed data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_from_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::WriteFrame","doc":"\u003cp\u003e\nWriteFrame writes a packet to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_strerror","goRep":[{"name":"ffgopeg/avutil.Strerror","doc":"\u003cp\u003e\nStrerror returns a descriptive string of the given return code.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_strerror\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_license","goRep":[{"name":"ffgopeg/avcodec.License","doc":"\u003cp\u003e\nLicense returns the libavcodec license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::log_level_offset","goRep":[{"name":"ffgopeg/avcodec.CodecContext::LogLevelOffset","doc":"\u003cp\u003e\nLogLevelOffset returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::log_level_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetLogLevelOffset","doc":"\u003cp\u003e\nSetLogLevelOffset sets something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::log_level_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_type","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetThreadType","doc":"\u003cp\u003e\nSetThreadType sets which multithreading methods to use.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_type\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::ThreadType","doc":"\u003cp\u003e\nThreadType returns which multithreading methods to use.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_id","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::CodecID","doc":"\u003cp\u003e\nCodecID returns the id of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_id\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_align_dimensions","goRep":[{"name":"ffgopeg/avcodec.CodecContext::AlignDimensions","doc":"\u003cp\u003e\nAlignDimensions modifies width and height values so that they will result in a memory buffer that is acceptable for the codec if you do not use any horizontal padding.\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\nC-Function: avcodec_align_dimensions\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qcompress","goRep":[{"name":"ffgopeg/avcodec.CodecContext::QCompress","doc":"\u003cp\u003e\nQCompress returns the amount of qscale change between easy \u0026amp; hard scenes. (0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qcompress\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetQCompress","doc":"\u003cp\u003e\nSetQCompress sets the amount of qscale change between easy \u0026amp; hard scenes. (0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qcompress\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_flush_buffers","goRep":[{"name":"ffgopeg/avcodec.CodecContext::FlushBuffers","doc":"\u003cp\u003e\nFlushBuffers resets the internal decoder state / flush internal buffers.\nShould be called e.g. when seeking or when switching to a different stream.\nC-Function: avcodec_flush_buffers\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_register","goRep":[{"name":"ffgopeg/avfilter.Filter::Register","doc":"\u003cp\u003e\nRegister registers a filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_register\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::trellis","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetTrellis","doc":"\u003cp\u003e\nSetTrellis sets the trellis RD quantization.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::trellis\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::Trellis","doc":"\u003cp\u003e\nTrellis returns the trellis RD quantization.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::trellis\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_parameters_from_contex","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ToParameters","doc":"\u003cp\u003e\nToParameters returns a CodecParameters instance from a CodecContext\nC-Function: avcodec_parameters_from_contex\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_video_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::VideoCodec","doc":"\u003cp\u003e\nVideoCodec returns the VideoCodec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_video_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_uncoded_frame_query","goRep":[{"name":"ffgopeg/avformat.FormatContext::WriteUncodedFrameQuery","doc":"\u003cp\u003e\nWriteUncodedFrameQuery tests whether a muxer supports uncoded frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_uncoded_frame_query\n\u003c/p\u003e\n"}]},{"ffmpeg":"avpriv_frame_get_metadatap","goRep":[{"name":"ffgopeg/avutil.Frame::Metadatap","doc":"\u003cp\u003e\nMetadatap returns metadatap.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avpriv_frame_get_metadatap\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_side_data","goRep":[{"name":"ffgopeg/avutil.Frame::SideData","doc":"\u003cp\u003e\nSideData returns the frames sidedata.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_subpel_quality","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MeSubpelQuality","doc":"\u003cp\u003e\nMeSubpelQuality returns the subpel ME quality.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_subpel_quality\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMeSubpelQuality","doc":"\u003cp\u003e\nSetMeSubpelQuality sets the subpel ME quality.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_subpel_quality\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::thread_safe_callbacks","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetThreadSafeCallbacks","doc":"\u003cp\u003e\nSetThreadSafeCallbacks sets whether or not the custom get_buffer() callback can be called synchronously from another threa, which allows faster multithreaded decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_safe_callbacks\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::ThreadSafeCallbacks","doc":"\u003cp\u003e\nThreadSafeCallbacks returns whether or not the custom get_buffer() callback can be called synchronously from another threa, which allows faster multithreaded decoding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::thread_safe_callbacks\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_compensation","goRep":[{"name":"ffgopeg/swresample.Context::SetCompensation","doc":"\u003cp\u003e\nSetCompensation activates resampling compensation (\u0026#34;soft\u0026#34; compensation).\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_compensation\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeContext","goRep":[{"name":"ffgopeg/swscale.Context::Free","doc":"\u003cp\u003e\nFree frees the swscaler context swsContext.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeContext\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qblur","goRep":[{"name":"ffgopeg/avcodec.CodecContext::QBlur","doc":"\u003cp\u003e\nQBlur returns the amount of qscale smoothing over time.\n(0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qblur\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetQBlur","doc":"\u003cp\u003e\nSetQBlur sets the amount of qscale smoothing over time.\n(0.0 - 1.0)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qblur\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_copy_props","goRep":[{"name":"ffgopeg/avcodec.Packet::CopyProps","doc":"\u003cp\u003e\nCopyProps copies only \u0026#34;properties\u0026#34; fields from src to dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_copy_props\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_uncoded_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::WriteUncodedFrame","doc":"\u003cp\u003e\nWriteUncodedFrame writes an uncoded frame to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_uncoded_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_configuration","goRep":[{"name":"ffgopeg/avcodec.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavcodec build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::profile","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Profile","doc":"\u003cp\u003e\nProfile returns the codec-specific bitstream restrictions that the stream conforms to.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::profile\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::last_predictor_count","goRep":[{"name":"ffgopeg/avcodec.CodecContext::LastPredictorCount","doc":"\u003cp\u003e\nLastPredictorCount returns the amount of previous MV predictors (2a+1 x 2a+1)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::last_predictor_count\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetLastPredictorCount","doc":"\u003cp\u003e\nSetLastPredictorCount sets the amount of previous MV predictors (2a+1 x 2a+1)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::last_predictor_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_max_available_vbv_use","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcMaxAvailableVbvUse","doc":"\u003cp\u003e\nRcMaxAvailableVbvUse returns the ratecontrol attempt to use, at maximum, of what can be used without an underflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_available_vbv_use\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcMaxAvailableVbvUse","doc":"\u003cp\u003e\nSetRcMaxAvailableVbvUse sets the ratecontrol attempt to use, at maximum, of what can be used without an underflow.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_available_vbv_use\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::block_align","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::BlockAlign","doc":"\u003cp\u003e\nBlockAlign returns the number of bytes per coded audio frame, required by some formats.\n\u003c/p\u003e\n\u003cp\u003e\nCorresponds to nBlockAlign in WAVEFORMATEX.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::block_align\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_input_audio_device_next","goRep":[{"name":"ffgopeg/avdevice.InputAudioDevices","doc":"\u003cp\u003e\nInputAudioDevices returns a channel which can be used to iterate over the input audio devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.InputAudioDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_input_audio_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_config","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::GraphConfig","doc":"\u003cp\u003e\nGraphConfig checks validity and configure all the links and formats in the graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_config\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_make_writable","goRep":[{"name":"ffgopeg/avutil.Frame::MakeWritable","doc":"\u003cp\u003e\nMakeWritable ensures that the frame data is writable, avoiding data copy if possible.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_make_writable\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_lowres","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Lowres","doc":"\u003cp\u003e\nLowres returns the low resolution decoding.\n1 equals 1/2 size. 2 equals 1/4 size.\nC-Function: av_codec_get_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::max_qdiff","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MaxQDiff","doc":"\u003cp\u003e\nMaxQDiff returns the maximum quantizer difference between frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_qdiff\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMaxQDiff","doc":"\u003cp\u003e\nSetMaxQDiff sets the maximum quantizer difference between frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_qdiff\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_filename_number_test","goRep":[{"name":"ffgopeg/avformat.AvFilenameNumberTest","doc":"\u003cp\u003e\nCheck whether filename actually is a numbered sequence generator.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_filename_number_test\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_iformat_next","goRep":[{"name":"ffgopeg/avformat.InputFormats","doc":"\u003cp\u003e\nInputFormats returns a channel which can be used to iterate over the input formats.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor in := range avformat.InputFormats() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_iformat_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_normalizeVec","goRep":[{"name":"ffgopeg/swscale.Vector::Normalize","doc":"\u003cp\u003e\nNormalize scales all the coefficients of a so that their sum equals height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_normalizeVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_range","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ColorRange","doc":"\u003cp\u003e\nColorRange returns the MPEG vs JPEG YUV range.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_range\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetColorRange","doc":"\u003cp\u003e\nSetColorRange sets the MPEG vs JPEG YUV range.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_tag","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::CodecTag","doc":"\u003cp\u003e\nCodecTag returns additional information about the codec (corrensponds to the AVI FOURCC).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_tag\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::temporal_cplx_masking","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetTemporalCplxMasking","doc":"\u003cp\u003e\nSetTemporalCplxMasking returns the temporal complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::temporal_cplx_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::TemporalCplxMasking","doc":"\u003cp\u003e\nTemporalCplxMasking returns the temporal complexity masking. 0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::temporal_cplx_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_frame_filename","goRep":[{"name":"ffgopeg/avformat.AvGetFrameFilename","doc":"\u003cp\u003e\nint av_get_frame_filename (char *buf, int buf_size, const char *path, int number)\nReturn in \u0026#39;buf\u0026#39; the path with \u0026#39;d\u0026#39; replaced by a number.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_frame_filename\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hex_dump","goRep":[{"name":"ffgopeg/avformat.AvHexDump","doc":"\u003cp\u003e\nSend a nice hexadecimal dump of a buffer to the specified file stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hex_dump\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_set_r_frame_rate","goRep":[{"name":"ffgopeg/avformat.Stream::StreamSetRFrameRate","doc":"\u003cp\u003e\nStreamSetRFrameRate does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_set_r_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::p_masking","goRep":[{"name":"ffgopeg/avcodec.CodecContext::PMasking","doc":"\u003cp\u003e\nPMasking returns the spatial complexity masking. 0 equals disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::p_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetPMasking","doc":"\u003cp\u003e\nSetPMasking sets the spatial complexity masking. 0 equals disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::p_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_top","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSkipTop","doc":"\u003cp\u003e\nSetSkipTop sets the number of macroblock rows at the top which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_top\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SkipTop","doc":"\u003cp\u003e\nSkipTop returns the number of macroblock rows at the top which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_top\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_tag","goRep":[{"name":"ffgopeg/avformat.AvCodecGetTag","doc":"\u003cp\u003e\nGet the codec tag for the given codec id id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_tag\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_packet","goRep":[{"name":"ffgopeg/avformat.IOContext::GetPacket","doc":"\u003cp\u003e\nGetPacket allocates and reads the payload of a packet and initialize its fields with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_side_data","goRep":[{"name":"ffgopeg/avformat.Stream::SideData","doc":"\u003cp\u003e\nSideData returns side information from stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_is_initialized","goRep":[{"name":"ffgopeg/swresample.Context::IsInitialized","doc":"\u003cp\u003e\nIsInitialized checks whether an swr context has been initialized or not.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_is_initialized\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodec::pix_fmts","goRep":[{"name":"ffgopeg/avcodec.Codec::PixFmts","doc":"\u003cp\u003e\nPixFmts returns an array of support pixel format, see AV_PIX_FMT_xxx.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodec::pix_fmts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacketSideData::size","goRep":[{"name":"ffgopeg/avcodec.PacketSideData::Size","doc":"\u003cp\u003e\nSize returns size of the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacketSideData::size\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_scaleVec","goRep":[{"name":"ffgopeg/swscale.Vector::Scale","doc":"\u003cp\u003e\nScale scales all the coefficients of a by the scalar value.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_scaleVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sub_charenc_mode","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SubCharencMode","doc":"\u003cp\u003e\nSubCharencMode returns the subtitles character encoding mode.\n\u003c/p\u003e\n\u003cp\u003e\nFormats or codecs might be adjusting this settings (if they are doing the conversion themselves for instance).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sub_charenc_mode\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_init","goRep":[{"name":"ffgopeg/swresample.Context::Init","doc":"\u003cp\u003e\nInit initializes the context after user parameters have been set.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_init\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_shrink_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::ShrinkSideData","doc":"\u003cp\u003e\nShrinkSideData shrinks the already allocated side data buffer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_shrink_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_unref","goRep":[{"name":"ffgopeg/avcodec.Packet::Unref","doc":"\u003cp\u003e\nUnref wipes a packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_unref\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_audio_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::AudioCodec","doc":"\u003cp\u003e\nAudioCodec returns the audio codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_audio_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_metadata_header_padding","goRep":[{"name":"ffgopeg/avformat.FormatContext::SetMetadataHeaderPadding","doc":"\u003cp\u003e\nSetMetadataHeaderPadding sets metadata header padding size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_metadata_header_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_int_list_length_for_size","goRep":[{"name":"ffgopeg/avutil.IntListLengthForSize","doc":"\u003cp\u003e\nIntListLengthForSize computes the length of an integer list.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_int_list_length_for_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_is_writable","goRep":[{"name":"ffgopeg/avutil.Frame::IsWritable","doc":"\u003cp\u003e\nIsWritable checks if the frame data is writable.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_is_writable\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_encode_subtitle","goRep":[{"name":"ffgopeg/avcodec.CodecContext::EncodeSubtitle","doc":"\u003cp\u003e\nEncodeSubtitle encodes a subtitle message.\nC-Function: avcodec_encode_subtitle\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_fill_audio_frame","goRep":[{"name":"ffgopeg/avcodec.Frame::FillAudioFrame","doc":"\u003cp\u003e\nFillAudioFrame fills the Frame audio data and linesize pointers.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_fill_audio_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_init_context","goRep":[{"name":"ffgopeg/swscale.Context::Init","doc":"\u003cp\u003e\nInit initializes the swscaler context sws_context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_init_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_cmp","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MeCmp","doc":"\u003cp\u003e\nMeCmp returns the motion estimation comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMeCmp","doc":"\u003cp\u003e\nSetMeCmp sets the motion estimation comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_copy_packet_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::CopyPacketSideData","doc":"\u003cp\u003e\nCopyPacketSideData copies packet side data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_copy_packet_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::data","goRep":[{"name":"ffgopeg/avcodec.Packet::Data","doc":"\u003cp\u003e\nData returns the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_pkt_dump2","goRep":[{"name":"ffgopeg/avformat.AvPktDump2","doc":"\u003cp\u003e\nSend a nice dump of a packet to the specified file stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_pkt_dump2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_guess_frame_rate","goRep":[{"name":"ffgopeg/avformat.FormatContext::GuessFrameRate","doc":"\u003cp\u003e\nGuessFrameRate guesses the frame rate, based on both the container and codec information.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_guess_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_new_stream","goRep":[{"name":"ffgopeg/avformat.FormatContext::NewStream","doc":"\u003cp\u003e\nNewStream adds a new stream to a media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_new_stream\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_version","goRep":[{"name":"ffgopeg/avcodec.Version","doc":"\u003cp\u003e\nVersion returns the LIBAvCODEC_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::cutoff","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Cutoff","doc":"\u003cp\u003e\nCutoff returns the audio cutoff bandwidth (0 means \u0026#34;automatic\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::cutoff\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetCutoff","doc":"\u003cp\u003e\nSetCutoff sets the audio cutoff bandwidth (0 means \u0026#34;automatic\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::cutoff\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_init_packet","goRep":[{"name":"ffgopeg/avcodec.Packet::Init","doc":"\u003cp\u003e\nInit initializes optional fields of a packet with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_init_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_merge_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::MergeSideData","doc":"\u003cp\u003e\nMergeSideData does something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_merge_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_app_to_dev_control_message","goRep":[{"name":"ffgopeg/avdevice.AppToDevControlMessage","doc":"\u003cp\u003e\nAppToDevControlMessage sends control message from application to device.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_app_to_dev_control_message\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_pause","goRep":[{"name":"ffgopeg/avformat.FormatContext::ReadPause","doc":"\u003cp\u003e\nReadPause pauses a network-based stream (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_pause\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::coded_width","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CodedWidth","doc":"\u003cp\u003e\nCodedWidth returns the bitstream width.\nIt may be different from the raw width. When the decoded frame is cropped before being output or lowres is enabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_width\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetCodedWidth","doc":"\u003cp\u003e\nSetCodedWidth sets the bitstream width.\nIt may be different from the raw width. When the decoded frame is cropped before being output or lowres is enabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_width\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_seek_preroll","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSeekPreroll","doc":"\u003cp\u003e\nSetSeekPreroll sets something undocumented.\nC-Function: av_codec_set_seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_version","goRep":[{"name":"ffgopeg/avdevice.Version","doc":"\u003cp\u003e\nVersion returns the libavdevice version.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_request_oldest","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::RequestOldestlink","doc":"\u003cp\u003e\nRequestOldestlink requests a frame on the oldest sink\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_request_oldest\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_license","goRep":[{"name":"ffgopeg/avformat.License","doc":"\u003cp\u003e\nLicense returns the libavformat license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_subtitle_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::SubtitleCodec","doc":"\u003cp\u003e\nSubtitleCodec returns the subtitle codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_subtitle_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_pix_fmt_loss","goRep":[{"name":"ffgopeg/avutil.GetPixFmtLoss","doc":"\u003cp\u003e\nGetPixFmtLoss returns what kind of losses will occur when converting from one specific pixel format to another.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_pix_fmt_loss\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_x_if_null","goRep":[{"name":"ffgopeg/avutil.XIfNull","doc":"\u003cp\u003e\nXIfNull returns x default pointer in case p is NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_x_if_null\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_close","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Close","doc":"\u003cp\u003e\nClose closes a given Context and free all the data associated with it (but not the Context itself).\nC-Function: avcodec_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_register_all","goRep":[{"name":"ffgopeg/avdevice.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes libavdevice and register all the input and output devices.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_unref","goRep":[{"name":"ffgopeg/avutil.Frame::Unref","doc":"\u003cp\u003e\nUnref unreferences all the buffers referenced by frame and reset the frame fields.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_unref\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedInput","goRep":[{"name":"ffgopeg/swscale.IsSupportedInput","doc":"\u003cp\u003e\nIsSupportedInput returns true if pix_fmt is a supported input format,false otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedInput\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::channel_layout","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ChannelLayout","doc":"\u003cp\u003e\nChannelLayout returns the audio channel layout.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::channel_layout\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetChannelLayout","doc":"\u003cp\u003e\nSetChannelLayout sets the audio channel layout.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::channel_layout\n\u003c/p\u003e\n"}]},{"ffmpeg":"avsubtitle_free","goRep":[{"name":"ffgopeg/avcodec.Subtitle::Free","doc":"\u003cp\u003e\nFree frees all allocated data of the Subtitle.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avsubtitle_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_create_filter","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::CreateFilter","doc":"\u003cp\u003e\nCreateFilter creates and add a filter instance into an existing graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_create_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_convertPalette8ToPacked24","goRep":[{"name":"ffgopeg/swscale.ConvertPalette8ToPacked24","doc":"\u003cp\u003e\nConvertPalette8ToPacked24 converts an 8-bit paletted frame into a frame with a color depth of 24 bits.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_convertPalette8ToPacked24\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_max_lowres","goRep":[{"name":"ffgopeg/avcodec.Codec::MaxLowres","doc":"\u003cp\u003e\nMaxLowres returns the maximum lowres supported by the decoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_max_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::b_quant_factor","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BQuantFactor","doc":"\u003cp\u003e\nBQuantFactor returns the qscale factor between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_factor\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBQuantFactor","doc":"\u003cp\u003e\nSetBQuantFactor sets the qscale factor between IP and B-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q*factor+offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q*factor+offset)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_factor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::flags","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Flags","doc":"\u003cp\u003e\nFlags returns the flags AV_CODEC_FLAG_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetFlags","doc":"\u003cp\u003e\nSetFlags set the flags AV_CODEC_FLAG_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_frame","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSkipFrame","doc":"\u003cp\u003e\nSetSkipFrame sets the skip decoding for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_frame\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SkipFrame","doc":"\u003cp\u003e\nSkipFrame returns the skip decoding for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bits_per_raw_sample","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::BitsPerRawSample","doc":"\u003cp\u003e\nBitsPerRawSample returns the number of valid bits in each output sample.\n\u003c/p\u003e\n\u003cp\u003e\nIf the sample format has more bits, the least significant bits are additional padding bits, which are always 0. Use right shifts to reduce the sample to its actual size. For example, audio formats with 24 bit samples will have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32. To get the original sample use \u0026#34;(int32_t)sample \u0026gt;\u0026gt; 8\u0026#34;.\u0026#34;\n\u003c/p\u003e\n\u003ch3 id=\"hdr-For_ADPCM_this_might_be_12_or_16_or_similar_Can_be_0\"\u003eFor ADPCM this might be 12 or 16 or similar Can be 0\u003c/h3\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bits_per_raw_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::trailing_padding","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::TrailingPadding","doc":"\u003cp\u003e\nTrailingPadding returns the amount of padding (in samples) appended by the encoder to the end of the audio. I.e. this number of decoded samples must be discarded by the caller from the end of the stream to get the original audio without any trailing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::trailing_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_input_video_device_next","goRep":[{"name":"ffgopeg/avdevice.InputVideoDevices","doc":"\u003cp\u003e\nInputVideoDevices returns a channel which can be used to iterate over the input video devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.InputVideoDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_input_video_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_process_command","goRep":[{"name":"ffgopeg/avfilter.FilterContext::ProcessCommand","doc":"\u003cp\u003e\nProcessCommand makes the filter instance process a command.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_process_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::block_align","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BlockAlign","doc":"\u003cp\u003e\nBlockAlign returns the number of bytes per packet if constant and known or 0.\nUsed by some WAV based audio codecs.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::block_align\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::codec_type","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CodecType","doc":"\u003cp\u003e\nCodecType return the codec type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::codec_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_set_qp_table","goRep":[{"name":"ffgopeg/avutil.Frame::SetQpTable","doc":"\u003cp\u003e\nSetQpTable sets the qp table.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_set_qp_table\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_inout_free","goRep":[{"name":"ffgopeg/avfilter.FilterInOut::Free","doc":"\u003cp\u003e\nFree frees the supplied list of FilterInOut and set *inout to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_inout_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_version","goRep":[{"name":"ffgopeg/avformat.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVFORMAT_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mv0_threshold","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Mv0Threshold","doc":"\u003cp\u003e\nMv0Threshold returns the mv0 threshold.\nValue depends on the compare function used for follpel ME.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mv0_threshold\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMv0Threshold","doc":"\u003cp\u003e\nSetMv0Threshold sets the mv0 threshold.\nValue depends on the compare function used for follpel ME.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mv0_threshold\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::channel_layout","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ChannelLayout","doc":"\u003cp\u003e\nChannelLayout returns the channel layout bitmask.\nMay be 0 if the channel layout is unknown or unspecified, otherwise the number of bits set bmust be equal to the channels field.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::channel_layout\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::b_quant_offset","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BQuantOffset","doc":"\u003cp\u003e\nBQuantOffset return the qscale offset between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBQuantOffset","doc":"\u003cp\u003e\nSetBQuantOffset return the qscale offset between IP and B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::b_quant_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::dia_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DiaSize","doc":"\u003cp\u003e\nDiaSize returns ME diamod size and shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dia_size\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDiaSize","doc":"\u003cp\u003e\nSetDiaSize sets ME diamod size and shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dia_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_matrix","goRep":[{"name":"ffgopeg/swresample.Context::SetMatrix","doc":"\u003cp\u003e\nSetMatrix sets a customized remix matrix.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_matrix\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_find_default_stream_index","goRep":[{"name":"ffgopeg/avformat.FormatContext::FindDefaultStreamIndex","doc":"\u003cp\u003e\nFindDefaultStreamIndex returns the default stream index.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_find_default_stream_index\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_set_channel_mapping","goRep":[{"name":"ffgopeg/swresample.Context::SetChannelMapping","doc":"\u003cp\u003e\nSetChannelMapping sets a customized input channel mapping.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_set_channel_mapping\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::nsse_weight","goRep":[{"name":"ffgopeg/avcodec.CodecContext::NsseWeight","doc":"\u003cp\u003e\nNsseWeight returns the noise vs sse weight for the nsse comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::nsse_weight\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::frame_number","goRep":[{"name":"ffgopeg/avcodec.CodecContext::FrameNumber","doc":"\u003cp\u003e\nFrameNumber returns the Frame counter, set by libavcodec.\n\u003c/p\u003e\n\u003cp\u003e\nDecoding: Total number of frames returned from the decoder so far.\nEncoding: Total number of frames passed to the encoder so far.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::frame_number\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_cmp","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MbCmp","doc":"\u003cp\u003e\nMbCmp returns the macroblock comparison function.\n(not supported yet)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMbCmp","doc":"\u003cp\u003e\nSetMbCmp sets the macroblock comparison function.\n(not supported yet)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::codec_type","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::CodecType","doc":"\u003cp\u003e\nCodecType returns the general type of the encoded data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::codec_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::stream_index","goRep":[{"name":"ffgopeg/avcodec.Packet::StreamIndex","doc":"\u003cp\u003e\nStreamIndex returns the index of the stream this packet originated from.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::stream_index\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_queue_attached_pictures","goRep":[{"name":"ffgopeg/avformat.FormatContext::QueueAttachedPictures","doc":"\u003cp\u003e\nQueueAttachedPictures is undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_queue_attached_pictures\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_video_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::SetVideoCodec","doc":"\u003cp\u003e\nSetVideoCodec sets the video codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_video_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_enum_to_chroma_pos","goRep":[{"name":"ffgopeg/avcodec.ChromaLocation::ToChromaPos","doc":"\u003cp\u003e\nToChromaPos converts the ChromaLocation to swscale x/y chroma position.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_enum_to_chroma_pos\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_pkt_timebase","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetPktTimebase","doc":"\u003cp\u003e\nSetPktTimebase sets the packet timebase.\nC-Function: av_codec_set_pkt_timebase\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::channels","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Channels","doc":"\u003cp\u003e\nChannels return the number of audio channels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::channels\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_license","goRep":[{"name":"ffgopeg/avfilter.License","doc":"\u003cp\u003e\nLicense returns the libavfilter license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_network_init","goRep":[{"name":"ffgopeg/avformat.NetworkInit","doc":"\u003cp\u003e\nNetworkInit does global initialization of network components.\n\u003c/p\u003e\n\u003cp\u003e\nThis is optional, but recommended, since it avoids the overhead of implicitly doing the setup for each session.\n\u003c/p\u003e\n\u003cp\u003e\nCalling this function will become mandatory if using network protocols at some major version bump.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_network_init\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_seek_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::SeekFrame","doc":"\u003cp\u003e\nSeekFrame seeks to the keyframe at timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_seek_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_subtitle_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::SetSubtitleCodec","doc":"\u003cp\u003e\nSetSubtitleCodec sets the subtitle codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_subtitle_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_config_frame","goRep":[{"name":"ffgopeg/swresample.Context::ConfigFrame","doc":"\u003cp\u003e\nConfigFrame configures or reconfigures the Context using the information provided by the AvFrames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_config_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_profile_name","goRep":[{"name":"ffgopeg/avcodec.Codec::ProfileName","doc":"\u003cp\u003e\nProfileName returns a name for the specified profile, if available.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_profile_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::ticks_per_frame","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetTicksPerFrame","doc":"\u003cp\u003e\nSetTicksPerFrame sets the ticks per frame.\n\u003c/p\u003e\n\u003cp\u003e\nFor some codecs, the time base is closer to the field rate than the frame rate.\n\u003c/p\u003e\n\u003cp\u003e\nMost notably, H.264 and MPEG-2 specify time_base as half of frame duration if no telecine is used ...\n\u003c/p\u003e\n\u003cp\u003e\nSet to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ticks_per_frame\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::TicksPerFrame","doc":"\u003cp\u003e\nTicksPerFrame returns the ticks per frame.\n\u003c/p\u003e\n\u003cp\u003e\nFor some codecs, the time base is closer to the field rate than the frame rate.\n\u003c/p\u003e\n\u003cp\u003e\nMost notably, H.264 and MPEG-2 specify time_base as half of frame duration if no telecine is used ...\n\u003c/p\u003e\n\u003cp\u003e\nSet to time_base ticks per frame. Default 1, e.g., H.264/MPEG-2 set it to 2.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::ticks_per_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_drop_output","goRep":[{"name":"ffgopeg/swresample.Context::DropOutput","doc":"\u003cp\u003e\nDropOutput drops the specified number of output samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_drop_output\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::flags","goRep":[{"name":"ffgopeg/avcodec.Packet::Flags","doc":"\u003cp\u003e\nFlags returns a combination of AV_PKT_FLAG values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_network_deinit","goRep":[{"name":"ffgopeg/avformat.NetworkDeinit","doc":"\u003cp\u003e\nNetworkDeinit undoes the initialization done by avformat_network_init.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_network_deinit\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_getCoefficients","goRep":[{"name":"ffgopeg/swscale.Coefficients","doc":"\u003cp\u003e\nCoefficients returns a pointer to yuv\u0026lt;-\u0026gt;rgb coefficients for the given colorspace suitable for sws_setColorspaceDetails().\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_getCoefficients\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::workaround_bugs","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetWorkaroundBugs","doc":"\u003cp\u003e\nSetWorkaroundBugs sets which bufs to work around.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::workaround_bugs\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::WorkaroundBugs","doc":"\u003cp\u003e\nWorkaroundBugs returns which bufs to work around.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::workaround_bugs\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::dts","goRep":[{"name":"ffgopeg/avcodec.Packet::Dts","doc":"\u003cp\u003e\nDts returns the decompression timestamp in AVStream-\u0026gt;time_base units; the time at which the packet is decompressed.\nCan be AV_NOPTS_VALUE if it is not stored in the file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::dts\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_descriptor_get","goRep":[{"name":"ffgopeg/avcodec.CodecId::Descriptor","doc":"\u003cp\u003e\nDescriptor returns the CodecDescriptor of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_descriptor_get\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_shrink_packet","goRep":[{"name":"ffgopeg/avcodec.Packet::ShrinkPacket","doc":"\u003cp\u003e\nShrinkPacket reduces packet size, correctly zeroing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_shrink_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_capabilities_free","goRep":[{"name":"ffgopeg/avdevice.CapabilitiesFree","doc":"\u003cp\u003e\nCapabilitiesFree frees resources created by CapabilitiesCreate()\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_capabilities_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_close_input","goRep":[{"name":"ffgopeg/avformat.FormatContext::Close","doc":"\u003cp\u003e\nClose closes an opened input Context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_close_input\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_packed_sample_fmt","goRep":[{"name":"ffgopeg/avutil.SampleFormat::Packed","doc":"\u003cp\u003e\nPacked returns the packed variant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_packed_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedEndiannessConversion","goRep":[{"name":"ffgopeg/swscale.IsSupportedEndiannessConversion","doc":"\u003cp\u003e\nIsSupportedEndiannessConversion returns true if endianess conversion is supported.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedEndiannessConversion\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::keyint_min","goRep":[{"name":"ffgopeg/avcodec.CodecContext::KeyintMin","doc":"\u003cp\u003e\nKeyintMin returns the minimum GOP size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::keyint_min\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetKeyintMin","doc":"\u003cp\u003e\nSetKeyintMin sets the minimum GOP size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::keyint_min\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::level","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Level","doc":"\u003cp\u003e\nLevel returns the level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::level\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetLevel","doc":"\u003cp\u003e\nSetLevel sets the level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::level\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bit_rate","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BitRate","doc":"\u003cp\u003e\nBitRate returns the average bit rate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBitRate","doc":"\u003cp\u003e\nSetBitRate sets the average bit rate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_send_frame","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SendFrame","doc":"\u003cp\u003e\nSendFrame sends a frame as input to the encoder.\nC-Function: avcodec_send_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_new_packet","goRep":[{"name":"ffgopeg/avcodec.Packet::NewPacket","doc":"\u003cp\u003e\nNewPacket allocates the payload of a packet and initialize its fields with default values.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_new_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_query_codec","goRep":[{"name":"ffgopeg/avformat.AvformatQueryCodec","doc":"\u003cp\u003e\nTest if the given container can store a codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_query_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_descriptor_next","goRep":[{"name":"ffgopeg/avcodec.RegisteredCodecDescriptors","doc":"\u003cp\u003e\nRegisteredCodecDescriptors returns a channel which can be used to iterate over the registered CodecDescriptor.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_descriptor_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor cc := range avcodec.RegisteredCodecDescriptors() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"av_codec_is_decoder","goRep":[{"name":"ffgopeg/avcodec.Codec::IsDecoder","doc":"\u003cp\u003e\nIsDecoder returns true if the codec is an decoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_is_decoder\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_free","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::Free","doc":"\u003cp\u003e\nFree frees a graph, destroy its links, and set *graph to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_sdp_create","goRep":[{"name":"ffgopeg/avformat.AvSdpCreate","doc":"\u003cp\u003e\nGenerate an SDP for an RTP session.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_sdp_create\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_move_ref","goRep":[{"name":"ffgopeg/avutil.FrameMoveRef","doc":"\u003cp\u003e\nFrameMoveRef moves everythnig contained in src to dst and reset src.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_move_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_version","goRep":[{"name":"ffgopeg/swresample.Version","doc":"\u003cp\u003e\nVersion returns the swresample version.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_convertPalette8ToPacked32","goRep":[{"name":"ffgopeg/swscale.ConvertPalette8ToPacked32","doc":"\u003cp\u003e\nConvertPalette8ToPacked32 converts an 8-bit paletted frame into a frame with a color depth of 32 bits.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_convertPalette8ToPacked32\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::gop_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::GopSize","doc":"\u003cp\u003e\nGopSize returns the number of pictures in a group of pictures, or 0 for intra_only.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::gop_size\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetGopSize","doc":"\u003cp\u003e\nSetGopSize sets the number of pictures in a group of pictures, or 0 for intra_only.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::gop_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_configuration","goRep":[{"name":"ffgopeg/avdevice.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavdevice build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_chroma_sub_sample","goRep":[{"name":"ffgopeg/avutil.PixelFormat::ChromaSubSample","doc":"\u003cp\u003e\nChromaSubSample grants access log2_chroma_w log2_chroma_h from the pixel format AvPixFmtDescriptor.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_chroma_sub_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg/avutil.PixelFormat::ToCodecTag","doc":"\u003cp\u003e\nToCodecTag returns a value representing the fourCC code associated to the pixel format pix_fmt, or 0 if no associated fourCC code can be found.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_chroma_sub_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_alloc_set_opts","goRep":[{"name":"ffgopeg/swresample.Context::SetOpts","doc":"\u003cp\u003e\nSetOpts allocates Context if needed and set/reset common parameters.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_alloc_set_opts\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::height","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Height","doc":"\u003cp\u003e\nHeight returns the height of the video frame in pixels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::height\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::width","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Width","doc":"\u003cp\u003e\nWidth returns the width of the video frame in pixels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::width\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::width","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetWidth","doc":"\u003cp\u003e\nSetWidth sets the raw image width.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::width\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::Width","doc":"\u003cp\u003e\nWidth returns the raw image width.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::width\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::seek_preroll","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::SeekPreroll","doc":"\u003cp\u003e\nSeekPreroll returns the number of sample to skip after a discontinuity.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_next","goRep":[{"name":"ffgopeg/avcodec.RegisteredCodecs","doc":"\u003cp\u003e\nRegisteredCodecs returns a channel which can be used to iterate over the registered codecs.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor codec := range avcodec.RegisteredCodecs() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVCodecContext::extradata_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ExtradataSize","doc":"\u003cp\u003e\nExtradataSize returns the extradata size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::extradata_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_capabilities_create","goRep":[{"name":"ffgopeg/avdevice.CapabilitiesCreate","doc":"\u003cp\u003e\nCapabilitiesCreate initializes capabilities probing API based on AvOption API.\n\u003c/p\u003e\n\u003cp\u003e\nCapabilitiesFree() must be called when query capabilities API is not used anymore.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_capabilities_create\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse_ptr","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::ParsePtr","doc":"\u003cp\u003e\nParsePtr adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse_ptr\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_link_free","goRep":[{"name":"ffgopeg/avfilter.FilterLink::Free","doc":"\u003cp\u003e\nFree the link in *link, and set its pointer to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_link_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_codec_descriptor","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CodecDescriptor","doc":"\u003cp\u003e\nCodecDescriptor returns the CodecDescriptor.\nC-Function: av_codec_get_codec_descriptor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::pix_fmt","goRep":[{"name":"ffgopeg/avcodec.CodecContext::PixFmt","doc":"\u003cp\u003e\nPixFmt returns the pixel format, see AV_PIX_FMT_xxx.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pix_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetPixFmt","doc":"\u003cp\u003e\nSetPixFmt sets the pixel format, see AV_PIX_FMT_xxx.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pix_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_ref","goRep":[{"name":"ffgopeg/avcodec.Packet::Ref","doc":"\u003cp\u003e\nRef sets up a new reference to the data described by a given packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_split_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::SplitSideData","doc":"\u003cp\u003e\nSplitSideData does something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_split_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::chroma_sample_location","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ChromaSampleLocation","doc":"\u003cp\u003e\nChromaSampleLocation returns the location of chroma samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::chroma_sample_location\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetChromaSampleLocation","doc":"\u003cp\u003e\nSetChromaSampleLocation sets the location of chroma samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::chroma_sample_location\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_lmax","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MbLMax","doc":"\u003cp\u003e\nMbLMax returns the maximum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmax\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMbLMax","doc":"\u003cp\u003e\nSetMbLMax returns the maximum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmax\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::lumi_masking","goRep":[{"name":"ffgopeg/avcodec.CodecContext::LumiMasking","doc":"\u003cp\u003e\nLumiMasking retunrs the level of luminance masking.\n0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::lumi_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetLumiMasking","doc":"\u003cp\u003e\nSetLumiMasking retunrs the level of luminance masking.\n0 means disabled.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::lumi_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::max_b_frames","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MaxBFrames","doc":"\u003cp\u003e\nMaxBFrames returns the maximum nomber of B-frames between non-B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nNote: The output will be delayed by max_b_frames+1 relative to the input.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_b_frames\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMaxBFrames","doc":"\u003cp\u003e\nSetMaxBFrames sets the maximum nomber of B-frames between non-B-frames.\n\u003c/p\u003e\n\u003cp\u003e\nNote: The output will be delayed by max_b_frames+1 relative to the input.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::max_b_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_is_encoder","goRep":[{"name":"ffgopeg/avcodec.Codec::IsEncoder","doc":"\u003cp\u003e\nIsEncoder returns true if the codec is an encoder.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_is_encoder\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::height","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Height","doc":"\u003cp\u003e\nHeight returns the raw image height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::height\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::qmax","goRep":[{"name":"ffgopeg/avcodec.CodecContext::QMax","doc":"\u003cp\u003e\nQMax returns the maximum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmax\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetQMax","doc":"\u003cp\u003e\nSetQMax sets the maximum quantizer.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::qmax\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sample_fmt","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SampleFmt","doc":"\u003cp\u003e\nSampleFmt returns the audio sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetSampleFmt","doc":"\u003cp\u003e\nSetSampleFmt sets the audio sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_close","goRep":[{"name":"ffgopeg/avcodec.CodecParserContext::Close","doc":"\u003cp\u003e\nClose closes the CodecParserContext.\nC-Function: av_parser_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_send_command","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::SendCommand","doc":"\u003cp\u003e\nSendCommand sends a command to one or more filter instances.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_send_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::channels","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Channels","doc":"\u003cp\u003e\nChannels returns the number of audio channels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::channels\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetChannels","doc":"\u003cp\u003e\nSetChannels sets the number of audio channels.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::channels\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_decision","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MbDecision","doc":"\u003cp\u003e\nMbDecision returns the macroblock decision mode.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_decision\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMbDecision","doc":"\u003cp\u003e\nSetMbDecision sets the macroblock decision mode.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_decision\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_range","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ColorRange","doc":"\u003cp\u003e\nColorRange returns additional colorspace characteristics.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_space","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ColorSpace","doc":"\u003cp\u003e\nColorSpace returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_space\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_count","goRep":[{"name":"ffgopeg/avfilter.FilterPadCount","doc":"\u003cp\u003e\nFilterPadCount gets the number of elements in a NULL-terminated array of FilterPads (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_display_rotation_get","goRep":[{"name":"ffgopeg/avformat.Stream::GetRotation","doc":"\u003cp\u003e\nGetRotation does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_display_rotation_get\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_bottom","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSkipBottom","doc":"\u003cp\u003e\nSetSkipBottom sets the number of macroblocks rows at the bottom which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_bottom\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SkipBottom","doc":"\u003cp\u003e\nSkipBottom returns the number of macroblocks rows at the bottom which are skipped.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_bottom\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bits_per_coded_sample","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::BitsPerCodedSample","doc":"\u003cp\u003e\nBitsPerCodedSample returns the number of bits per sample in the coded words.\n\u003c/p\u003e\n\u003cp\u003e\nThis is basically the bitrate per sample. It is mandatory for a bunch of formats to actually decode them. It\u0026#39;s the number of bits for one sample.\n\u003c/p\u003e\n\u003cp\u003e\nThis could be for example 4 for ADPCM For PCM formats this matches bits_per_raw_sample. Can be 0\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bits_per_coded_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::bit_rate","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::BitRate","doc":"\u003cp\u003e\nBitRate returns the average bitrate of the encoded data (in bits per second).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::bit_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_configuration","goRep":[{"name":"ffgopeg/avfilter.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavfilter build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_register_all","goRep":[{"name":"ffgopeg/avfilter.RegisterAll","doc":"\u003cp\u003e\nRegisterAll initializes the filter system.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_insert_filter","goRep":[{"name":"ffgopeg/avfilter.FilterLink::InsertFilter","doc":"\u003cp\u003e\nInsertFilter insterts a filter in the middle of an existing link.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_insert_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_guess_sample_aspect_ratio","goRep":[{"name":"ffgopeg/avformat.FormatContext::GuessSampleAspectRatio","doc":"\u003cp\u003e\nGuessSampleAspectRatio guesses the sample aspect ratio of a frame, based on both the stream and the frame aspect ratio.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_guess_sample_aspect_ratio\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_interleaved_write_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::InterleavedWriteFrame","doc":"\u003cp\u003e\nInterleavedWriteFrame writes a packet to an output media file ensuring correct interleaving.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_interleaved_write_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_register_all","goRep":[{"name":"ffgopeg/avcodec.RegisterAll","doc":"\u003cp\u003e\nRegisterAll registers all the codecs, parsers and bitstream filters which were enabled at configuration time.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_register_all\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_idct","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSkipIdct","doc":"\u003cp\u003e\nSetSkipIdct sets the skip IDCT/dequantization for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_idct\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SkipIdct","doc":"\u003cp\u003e\nSkipIdct returns the skip IDCT/dequantization for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_idct\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeFilter","goRep":[{"name":"ffgopeg/swscale.Filter::Free","doc":"\u003cp\u003e\nFree frees the filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeFilter\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_match_stream_specifier","goRep":[{"name":"ffgopeg/avformat.FormatContext::MatchStreamSpecifier","doc":"\u003cp\u003e\nMatchStreamSpecifier checks if the stream st contained in s is matched by the stream specifier spec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_match_stream_specifier\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_license","goRep":[{"name":"ffgopeg/swresample.License","doc":"\u003cp\u003e\nLicense returns the swresample license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_bits_per_sample","goRep":[{"name":"ffgopeg/avcodec.CodecId::BitsPerSample","doc":"\u003cp\u003e\nBitsPerSample returns codec bits per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bits_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_grow_packet","goRep":[{"name":"ffgopeg/avcodec.Packet::GrowPacket","doc":"\u003cp\u003e\nGrowPacket increases packet size, correctly zeroing padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_grow_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::size","goRep":[{"name":"ffgopeg/avcodec.Packet::Size","doc":"\u003cp\u003e\nSize returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_fmt_ctx_get_duration_estimation_method","goRep":[{"name":"ffgopeg/avformat.FormatContext::DurationEstimationMethod","doc":"\u003cp\u003e\nDurationEstimationMethod returns the method used to set ctx-\u0026gt;duration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_fmt_ctx_get_duration_estimation_method\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_set_audio_codec","goRep":[{"name":"ffgopeg/avformat.FormatContext::SetAudioCodec","doc":"\u003cp\u003e\nSetAudioCodec sets the audio codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_set_audio_codec\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_scale","goRep":[{"name":"ffgopeg/swscale.Context::Scale","doc":"\u003cp\u003e\nScale scales the image slice in srcSlice and put the resulting scaled slice in the image in dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_scale\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::frame_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::FrameSize","doc":"\u003cp\u003e\nFrameSize returns the number of samples per channel in an audio frame.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Set by libavcodec in avcodec_open2(). Each submitted frame except the last must contain exactly frame_size samples per channel. May be 0 when the codec has AV_CODEC_CAP_VARIABLE_FRAME_SIZE set, then the frame size is not restricted.\nDecoding: May be set by some decoders to indicate constant frame size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::frame_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::profile","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Profile","doc":"\u003cp\u003e\nProfile returns somthing undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::profile\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetProfile","doc":"\u003cp\u003e\nSetProfile sets somthing undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::profile\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::coded_height","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CodedHeight","doc":"\u003cp\u003e\nCodedHeight returns the bitstream height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetCodedHeight","doc":"\u003cp\u003e\nSetCodedHeight sets the bitstream height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetHeight","doc":"\u003cp\u003e\nSetHeight sets the raw image height.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::coded_height\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_decode_subtitle2","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DecodeSubtitle","doc":"\u003cp\u003e\nDecodeSubtitle decodes a subtitle message.\n\u003c/p\u003e\n\u003cp\u003e\nReturn a negative value on error, otherwise return the number of bytes used. If no subtitle could be decompressed, got_sub_ptr is zero. Otherwise, the subtitle is stored in *sub. Note that AV_CODEC_CAP_DR1 is not available for subtitle codecs. This is for simplicity, because the performance difference is expect to be negligible and reusing a get_buffer written for video codecs would probably perform badly due to a potentially very different allocation pattern.\n\u003c/p\u003e\n\u003cp\u003e\nSome decoders (those marked with CODEC_CAP_DELAY) have a delay between input and output. This means that for some packets they will not immediately produce decoded output and need to be flushed at the end of decoding to get all the decoded data. Flushing is done by calling this function with packets with avpkt-\u0026gt;data set to NULL and avpkt-\u0026gt;size set to 0 until it stops returning subtitles. It is safe to flush even those decoders that are not marked with CODEC_CAP_DELAY, then no subtitles will be returned.\nC-Function: avcodec_decode_subtitle2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::field_order","goRep":[{"name":"ffgopeg/avcodec.CodecContext::FieldOrder","doc":"\u003cp\u003e\nFieldOrder returns the field order.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::field_order\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetFieldOrder","doc":"\u003cp\u003e\nSetFieldOrder sets the field order.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::field_order\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::idct_algo","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IdctAlgo","doc":"\u003cp\u003e\nIdctAlgo returns the IDCT algorithm, see FF_IDCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::idct_algo\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetIdctAlgo","doc":"\u003cp\u003e\nSetIdctAlgo sets the IDCT algorithm, see FF_IDCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::idct_algo\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_change","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ParserChange","doc":"\u003cp\u003e\nParserChange is not yet completely implemented.\nC-Function: av_parser_change\nTODO\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_free_list_devices","goRep":[{"name":"ffgopeg/avdevice.DeviceInfoList::Free","doc":"\u003cp\u003e\nFree is a convenient function to free result of ListDevices().\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_free_list_devices\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_align_dimensions2","goRep":[{"name":"ffgopeg/avcodec.CodecContext::AlignDimensions2","doc":"\u003cp\u003e\nAlignDimensions2 modifies width and height values so that they will result in a memory buffer that is acceptable for the codec if you also ensure that all line sizes are a multiple of the respective linesize_align[i].\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\nC-Function: avcodec_align_dimensions2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bits_per_raw_sample","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BitsPerRawSample","doc":"\u003cp\u003e\nBitsPerRawSample returns the bits per sample/pixel of internal libavcodec pixel/sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_raw_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBitsPerRawSample","doc":"\u003cp\u003e\nSetBitsPerRawSample sets the bits per sample/pixel of internal libavcodec pixel/sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_raw_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_write_header","goRep":[{"name":"ffgopeg/avformat.FormatContext::WriteHeader","doc":"\u003cp\u003e\nWriteHeader allocates the stream private data and write the stream header to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_write_header\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_isSupportedOutput","goRep":[{"name":"ffgopeg/swscale.IsSupportedOutput","doc":"\u003cp\u003e\nIsSupportedOutput returns true if pix_fmt is a supported output format, false otherwise.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_isSupportedOutput\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_min_rate","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcMinRate","doc":"\u003cp\u003e\nRcMinRate returns the minimum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcMinRate","doc":"\u003cp\u003e\nSetRcMinRate sets the minimum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_min_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::frame_size","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::FrameSize","doc":"\u003cp\u003e\nFrameSize returns the audio frame size, if known.\nRequired by some formats to be static.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::frame_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_ref","goRep":[{"name":"ffgopeg/avutil.FrameRef","doc":"\u003cp\u003e\nFrameRef sets up a new reference to the data described by a given frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_free_context","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Free","doc":"\u003cp\u003e\nFree frees the codec context and everything associated with it.\nC-Function: avcodec_free_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_is_open","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IsOpen","doc":"\u003cp\u003e\nIsOpen returns true iff the CodecContext was opened and not yet closed.\nC-Function: avcodec_is_open\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_dict_count","goRep":[{"name":"ffgopeg/avformat.Dictionary::Count","doc":"\u003cp\u003e\nCount returns the number of entries in dictionary.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dict_count\n\u003c/p\u003e\n"},{"name":"ffgopeg/avformat.Dictionary::Get","doc":"\u003cp\u003e\nGet returns a dictionary entry with matching key.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_dict_count\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_r_frame_rate","goRep":[{"name":"ffgopeg/avformat.Stream::StreamGetRFrameRate","doc":"\u003cp\u003e\nStreamGetRFrameRate does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_r_frame_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_next","goRep":[{"name":"ffgopeg/avcodec.RegisteredCodecParsers","doc":"\u003cp\u003e\nRegisteredCodecParsers returns a channel which can be used to iterate over the registered CodecParser.\nC-Function: av_parser_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor cc := range avcodec.RegisteredCodecDescriptors() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVCodecContext::dct_algo","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DctAlgo","doc":"\u003cp\u003e\nDctAlgo returns the DCT algorithm, see FF_DCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dct_algo\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDctAlgo","doc":"\u003cp\u003e\nSetDctAlgo sets the DCT algorithm, see FF_DCT_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dct_algo\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_receive_frame","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ReceiveFrame","doc":"\u003cp\u003e\nReceiveFrame receives a frame as output from the decoder.\nC-Function: avcodec_receive_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_lowres","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetLowres","doc":"\u003cp\u003e\nSetLowres sets the low resolution decoding.\n1 equals 1/2 size. 2 equals 1/4 size.\nC-Function: av_codec_set_lowres\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::skip_loop_filter","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSkipLoopFilter","doc":"\u003cp\u003e\nSetSkipLoopFilter sets the skip loop filtering for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_loop_filter\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SkipLoopFilter","doc":"\u003cp\u003e\nSkipLoopFilter returns the skip loop filtering for selected frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::skip_loop_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::format","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Format","doc":"\u003cp\u003e\nFormat returns the pixel/sample format of video/audio data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::format\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_get_name","goRep":[{"name":"ffgopeg/avfilter.FilterPad::Name","doc":"\u003cp\u003e\nName returns the name of a FilterPad.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_get_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_pad_get_type","goRep":[{"name":"ffgopeg/avfilter.FilterPad::Type","doc":"\u003cp\u003e\nType returns the type of an FilterPad.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_pad_get_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_open2","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Open","doc":"\u003cp\u003e\nOpen initializes the CodecContext to use the given Codec.\nC-Function: avcodec_open2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::pre_dia_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::PreDiaSize","doc":"\u003cp\u003e\nPreDiaSize returns the ME prepass diamond size \u0026amp; shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pre_dia_size\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetPreDiaSize","doc":"\u003cp\u003e\nSetPreDiaSize sets the ME prepass diamond size \u0026amp; shape.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::pre_dia_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_getColorspaceDetails","goRep":[{"name":"ffgopeg/swscale.ColorspaceDetails","doc":"\u003cp\u003e\nColorspaceDetails returns the colorspace details.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_getColorspaceDetails\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_free_context","goRep":[{"name":"ffgopeg/avformat.FormatContext::Free","doc":"\u003cp\u003e\nFree frees the Context and all its streams.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_free_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_next_pts","goRep":[{"name":"ffgopeg/swresample.Context::NextPts","doc":"\u003cp\u003e\nNextPts converts the next timestamp from input to output timestamps are in 1/(in_sample_rate * out_sample_rate) units.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_next_pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hex_dump_log","goRep":[{"name":"ffgopeg/avformat.AvHexDumpLog","doc":"\u003cp\u003e\nSend a nice hexadecimal dump of a buffer to the log.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hex_dump_log\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_configuration","goRep":[{"name":"ffgopeg/avutil.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavutil build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_license","goRep":[{"name":"ffgopeg/avutil.License","doc":"\u003cp\u003e\nLicense returns the libavutil license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_alt_sample_fmt","goRep":[{"name":"ffgopeg/avutil.SampleFormat::Alternative","doc":"\u003cp\u003e\nAlternative returns the planar\u0026lt;-\u0026gt;packed alternative form of the given sample format, or AV_SAMPLE_FMT_NONE on error.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_alt_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bit_rate_tolerance","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BitRateTolerance","doc":"\u003cp\u003e\nBitRateTolerance returns the number of bits the bitstream is allowed to diverge from the reference.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate_tolerance\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBitRateTolerance","doc":"\u003cp\u003e\nSetBitRateTolerance sets the number of bits the bitstream is allowed to diverge from the reference.\nThe reference can be CBR (for CBR pass 1) or VBR (for VBR pass 2)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bit_rate_tolerance\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_new_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::NewSideData","doc":"\u003cp\u003e\nNewSideData allocates new information of a packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_new_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_index_search_timestamp","goRep":[{"name":"ffgopeg/avformat.AvIndexSearchTimestamp","doc":"\u003cp\u003e\nGet the index for a specific timestamp.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_index_search_timestamp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_inject_global_side_data","goRep":[{"name":"ffgopeg/avformat.FormatContext::InjectGlobalSideData","doc":"\u003cp\u003e\nInjectGlobalSideData will cause global side data to be injected in the next packet of each stream as well as after any subsequent seek.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_inject_global_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_probe_score","goRep":[{"name":"ffgopeg/avformat.FormatContext::ProbeScore","doc":"\u003cp\u003e\nProbeScore returns the probe score.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_probe_score\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_free","goRep":[{"name":"ffgopeg/avutil.Frame::Free","doc":"\u003cp\u003e\nFree frees the frame and any dynamically allocated objects in it, e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_convert_frame","goRep":[{"name":"ffgopeg/swresample.Context::ConvertFrame","doc":"\u003cp\u003e\nConvertFrame converts the samples in the input Frame and write them to the output Frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_convert_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_send_packet","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SendPacket","doc":"\u003cp\u003e\nSendPacket sends a packet as input to the decoder.\nC-Function: avcodec_send_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::level","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::Level","doc":"\u003cp\u003e\nLevel returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::level\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_range","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MeRange","doc":"\u003cp\u003e\nMeRange returns the maximum motion estimation search range in subpel units.\nIf 0 then no limit.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_range\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMeRange","doc":"\u003cp\u003e\nSetMeRange sets the maximum motion estimation search range in subpel units.\nIf 0 then no limit.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_range\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_buffer_size","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcBufferSize","doc":"\u003cp\u003e\nRcBufferSize returns the decoder bitstream buffer size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_buffer_size\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcBufferSize","doc":"\u003cp\u003e\nSetRcBufferSize sets the decoder bitstream buffer size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_buffer_size\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::strict_std_compliance","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetStrictStdCompliance","doc":"\u003cp\u003e\nSetStrictStdCompliance sets the strictness to follow the standard (MPEG-4, ...).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::strict_std_compliance\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::StrictStdCompliance","doc":"\u003cp\u003e\nStrictStdCompliance returns the strictness to follow the standard (MPEG-4, ...).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::strict_std_compliance\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::time_base","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetTimeBase","doc":"\u003cp\u003e\nSetTimeBase sets the unit of time (in seconds).\n\u003c/p\u003e\n\u003cp\u003e\nThis is the fundamental unit of time (in seconds) in terms\nof which frame timestamps are represented. For fixed-fps content,\ntimebase should be 1/framerate and timestamp increments should be\nidentically 1.\nThis often, but not always is the inverse of the frame rate or field rate\nfor video. 1/time_base is not the average frame rate if the frame rate is not\nconstant.\n\u003c/p\u003e\n\u003cp\u003e\nLike containers, elementary streams also can store timestamps, 1/time_base\nis the unit in which these timestamps are specified.\nAs example of such codec time base see ISO/IEC 14496-2:2001(E)\nvop_time_increment_resolution and fixed_vop_rate\n(fixed_vop_rate == 0 implies that it is different from the framerate)\n\u003c/p\u003e\n\u003cpre\u003e- encoding: MUST be set by user.\n\u003c/pre\u003e\n\u003cp\u003e\n- decoding: the use of this field for decoding is deprecated.\n\u003c/p\u003e\n\u003cpre\u003eUse framerate instead.\n\u003c/pre\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::time_base\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::TimeBase","doc":"\u003cp\u003e\nTimeBase returns the unit of time (in seconds).\n\u003c/p\u003e\n\u003cp\u003e\nThis is the fundamental unit of time (in seconds) in terms\nof which frame timestamps are represented. For fixed-fps content,\ntimebase should be 1/framerate and timestamp increments should be\nidentically 1.\nThis often, but not always is the inverse of the frame rate or field rate\nfor video. 1/time_base is not the average frame rate if the frame rate is not\nconstant.\n\u003c/p\u003e\n\u003cp\u003e\nLike containers, elementary streams also can store timestamps, 1/time_base\nis the unit in which these timestamps are specified.\nAs example of such codec time base see ISO/IEC 14496-2:2001(E)\nvop_time_increment_resolution and fixed_vop_rate\n(fixed_vop_rate == 0 implies that it is different from the framerate)\n\u003c/p\u003e\n\u003cpre\u003e- encoding: MUST be set by user.\n\u003c/pre\u003e\n\u003cp\u003e\n- decoding: the use of this field for decoding is deprecated.\n\u003c/p\u003e\n\u003cpre\u003eUse framerate instead.\n\u003c/pre\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::time_base\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_move_ref","goRep":[{"name":"ffgopeg/avcodec.Packet::MoveRef","doc":"\u003cp\u003e\nMoveRef moves every field in src to dst and reset src.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_move_ref\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_new_program","goRep":[{"name":"ffgopeg/avformat.FormatContext::NewProgram","doc":"\u003cp\u003e\nNewProgram creates a new Program.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_new_program\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::compression_level","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CompressionLevel","doc":"\u003cp\u003e\nCompressionLevel returns the compression level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::compression_level\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetCompressionLevel","doc":"\u003cp\u003e\nSetCompressionLevel sets the compression level.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::compression_level\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::err_recognition","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ErrRecognition","doc":"\u003cp\u003e\nErrRecognition returns the error recognition.\nIt may misdetect some more or less valid parts as errors.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::err_recognition\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetErrRecognition","doc":"\u003cp\u003e\nSetErrRecognition sets the error recognition.\nIt may misdetect some more or less valid parts as errors.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::err_recognition\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_media_type_string","goRep":[{"name":"ffgopeg/avutil.MediaTypeString","doc":"\u003cp\u003e\nMediaTypeString returns a string describing the media_type enum, NULL if media_type is unknown.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_media_type_string\n\u003c/p\u003e\n"}]},{"ffmpeg":"avutil_version","goRep":[{"name":"ffgopeg/avutil.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVUTIL_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avutil_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::codec_id","goRep":[{"name":"ffgopeg/avcodec.CodecContext::CodecID","doc":"\u003cp\u003e\nCodecID returns the codec id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::codec_id\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_parameters_to_context","goRep":[{"name":"ffgopeg/avcodec.CodecContext::FromParameters","doc":"\u003cp\u003e\nFromParameters fills the previously initializes CodecContext with the given parameters.\nC-Function: avcodec_parameters_to_context\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_receive_packet","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ReceivePacket","doc":"\u003cp\u003e\nReceivePacket receives a packet as output from the decoder.\nC-Function: avcodec_receive_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_free","goRep":[{"name":"ffgopeg/avfilter.FilterContext::Free","doc":"\u003cp\u003e\nFree frees a filter context.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_set_auto_convert","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::SetAutoConvert","doc":"\u003cp\u003e\nSetAutoConvert enables or disables automatic format conversion inside the graph.\nflags can be any of the AVFILTER_AUTO_CONVERT_* constants.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_set_auto_convert\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_copy_props","goRep":[{"name":"ffgopeg/avutil.CopyProps","doc":"\u003cp\u003e\nCopyProps copies only \u0026#34;metadata\u0026#34; fields from src to dst.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_copy_props\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::active_thread_type","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ActiveThreadType","doc":"\u003cp\u003e\nActiveThreadType returns which multithreading methods are used by the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::active_thread_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_audio_frame_duration","goRep":[{"name":"ffgopeg/avcodec.CodecContext::AudioFrameDuration","doc":"\u003cp\u003e\nAudioFrameDuration returns audio frame duration, or 0 if not able to determine.\nC-Function: av_get_audio_frame_duration\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_convert","goRep":[{"name":"ffgopeg/swresample.Context::Convert","doc":"\u003cp\u003e\nConvert core conversion functions. Convert audio\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_convert\n\u003c/p\u003e\n"}]},{"ffmpeg":"sws_freeVec","goRep":[{"name":"ffgopeg/swscale.Vector::Free","doc":"\u003cp\u003e\nFree frees the vector.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: sws_freeVec\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::flags2","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Flags2","doc":"\u003cp\u003e\nFlags2 returns the flags AV_CODEC_FLAG2_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags2\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetFlags2","doc":"\u003cp\u003e\nSetFlags2 sets the flags AV_CODEC_FLAG2_*.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::flags2\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_pre_cmp","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MePreCmp","doc":"\u003cp\u003e\nMePreCmp returns the motion estimation prepass comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_pre_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMePreCmp","doc":"\u003cp\u003e\nSetMePreCmp sets the motion estimation prepass comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_pre_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_rescale_ts","goRep":[{"name":"ffgopeg/avcodec.Packet::RescaleTs","doc":"\u003cp\u003e\nRescaleTs converts valid timing fields (timestamps / durations) in a packet from one timebase to another.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_rescale_ts\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_play","goRep":[{"name":"ffgopeg/avformat.FormatContext::ReadPlay","doc":"\u003cp\u003e\nReadPlay starts playing a network-based stream (e.g.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_play\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_parser","goRep":[{"name":"ffgopeg/avformat.Stream::StreamGetParser","doc":"\u003cp\u003e\nStreamGetParser does something undocumented.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_parser\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::color_trc","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ColorTrc","doc":"\u003cp\u003e\nColorTrc returns the color transfer characteristic.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_trc\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetColorTrc","doc":"\u003cp\u003e\nSetColorTrc sets the color transfer characteristic.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::color_trc\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::error_concealment","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ErrorConcealment","doc":"\u003cp\u003e\nErrorConcealment returns error concealment flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::error_concealment\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetErrorConcealment","doc":"\u003cp\u003e\nSetErrorConcealment sets error concealment flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::error_concealment\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::has_b_frames","goRep":[{"name":"ffgopeg/avcodec.CodecContext::HasBFrames","doc":"\u003cp\u003e\nHasBFrames returns the size of the reordering buffer in the decoder.\n\u003c/p\u003e\n\u003cp\u003e\nFor MPEG-2 it is 1 IPB or 0 low delay IP.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::has_b_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_name","goRep":[{"name":"ffgopeg/avcodec.CodecId::Name","doc":"\u003cp\u003e\nName returns the name of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::sample_rate","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::SampleRate","doc":"\u003cp\u003e\nSampleRate returns the number of audio samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::sample_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_pack_dictionary","goRep":[{"name":"ffgopeg/avcodec.Dictionary::Pack","doc":"\u003cp\u003e\nPack packs the dictionary for use in side_data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_pack_dictionary\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_url_split","goRep":[{"name":"ffgopeg/avformat.AvUrlSplit","doc":"\u003cp\u003e\nSplit a URL string into components.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_url_split\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_find_stream_info","goRep":[{"name":"ffgopeg/avformat.FormatContext::FindStreamInfo","doc":"\u003cp\u003e\nFindStreamInfo reads packets of a media file to get stream information.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_find_stream_info\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_codec_tag_string","goRep":[{"name":"ffgopeg/avcodec.GetCodecTagString","doc":"\u003cp\u003e\nGetCodecTagString returns a string representing the codec tag codec_tag.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_codec_tag_string\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::audio_service_type","goRep":[{"name":"ffgopeg/avcodec.CodecContext::AudioServiceType","doc":"\u003cp\u003e\nAudioServiceType returns the type of service that the audio stream conveys.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::audio_service_type\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetAudioServiceType","doc":"\u003cp\u003e\nSetAudioServiceType sets the type of service that the audio stream conveys.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::audio_service_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_format_get_metadata_header_padding","goRep":[{"name":"ffgopeg/avformat.FormatContext::MetadataHeaderPadding","doc":"\u003cp\u003e\nMetadataHeaderPadding returns metadata header padding size.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_format_get_metadata_header_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_free","goRep":[{"name":"ffgopeg/swresample.Context::Free","doc":"\u003cp\u003e\nFree frees Context destructor functions. Free the given Context and set the pointer to NULL.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_free\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_stream_get_end_pts","goRep":[{"name":"ffgopeg/avformat.Stream::StreamGetEndPts","doc":"\u003cp\u003e\nStreamGetEndPts returns the pts of the last muxed packet + its duration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_stream_get_end_pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_picture_type_char","goRep":[{"name":"ffgopeg/avutil.PictureTypeChar","doc":"\u003cp\u003e\nPictureTypeChar returns a single letter to describe the given picture type pict_type.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_picture_type_char\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_get_delay","goRep":[{"name":"ffgopeg/swresample.Context::GetDelay","doc":"\u003cp\u003e\nGetDelay gets the delay the next input sample will experience relative to the next output sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_get_delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_output_audio_device_next","goRep":[{"name":"ffgopeg/avdevice.OutputAudioDevices","doc":"\u003cp\u003e\nOutputAudioDevices returns a channel which can be used to iterate over the output audio devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.OutputAudioDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_output_audio_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_register_output_format","goRep":[{"name":"ffgopeg/avformat.OutputFormat::Register","doc":"\u003cp\u003e\nRegister registers the OutputFormat.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_register_output_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_exact_bits_per_sample","goRep":[{"name":"ffgopeg/avcodec.CodecId::ExactBitsPerSample","doc":"\u003cp\u003e\nExactBitsPerSample returns codec bits per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_exact_bits_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_alloc_filter","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::NewFilterContext","doc":"\u003cp\u003e\nNewFilterContext creates a new filter instance in a filter graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_alloc_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"swresample_configuration","goRep":[{"name":"ffgopeg/swresample.Configuration","doc":"\u003cp\u003e\nConfiguration returns the build time configuration of swresample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swresample_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_chroma_intra_matrix","goRep":[{"name":"ffgopeg/avcodec.CodecContext::ChromaIntraMatrix","doc":"\u003cp\u003e\nChromaIntraMatrix returns something undocumented.\nC-Function: av_codec_get_chroma_intra_matrix\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetChromaIntraMatrix","doc":"\u003cp\u003e\nSetChromaIntraMatrix sets something undocumented.\nC-Function: av_codec_get_chroma_intra_matrix\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::request_sample_fmt","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RequestSampleFmt","doc":"\u003cp\u003e\nRequestSampleFmt returns the desired sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::request_sample_fmt\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRequestSampleFmt","doc":"\u003cp\u003e\nSetRequestSampleFmt sets the desired sample format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::request_sample_fmt\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_read_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::ReadFrame","doc":"\u003cp\u003e\nReadFrame returns the next frame of a stream.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_read_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_buffer","goRep":[{"name":"ffgopeg/avutil.Frame::NewBuffer","doc":"\u003cp\u003e\nNewBuffer allocates new buffer(s) for audio or video data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_buffer\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::rc_max_rate","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RcMaxRate","doc":"\u003cp\u003e\nRcMaxRate returns the maximum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRcMaxRate","doc":"\u003cp\u003e\nSetRcMaxRate sets the maximum bitrate.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::rc_max_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::field_order","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::FieldOrder","doc":"\u003cp\u003e\nFieldOrder returns the order of the fields in interlaced video.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::field_order\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::delay","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Delay","doc":"\u003cp\u003e\nDelay returns the codec delay.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Number of frames delay there will be from the encoder input to the decoder output. (we assume the decoder matches the spec) Decoding: Number of frames delay in addition to what a standard decoder as specified in the spec would produce.\n\u003c/p\u003e\n\u003cp\u003e\nVideo: Number of frames the decoded output will be delayed relative to the encoded input.\n\u003c/p\u003e\n\u003cp\u003e\nAudio: For encoding, this field is unused (see initial_padding).\n\u003c/p\u003e\n\u003cp\u003e\nFor decoding, this is the number of samples the decoder needs to output before the decoder\u0026#39;s output is valid. When seeking, you should start decoding this many samples prior to your desired seek point.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::delay\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDelay","doc":"\u003cp\u003e\nSetDelay sets the codec delay.\n\u003c/p\u003e\n\u003cp\u003e\nEncoding: Number of frames delay there will be from the encoder input to the decoder output. (we assume the decoder matches the spec) Decoding: Number of frames delay in addition to what a standard decoder as specified in the spec would produce.\n\u003c/p\u003e\n\u003cp\u003e\nVideo: Number of frames the decoded output will be delayed relative to the encoded input.\n\u003c/p\u003e\n\u003cp\u003e\nAudio: For encoding, this field is unused (see initial_padding).\n\u003c/p\u003e\n\u003cp\u003e\nFor decoding, this is the number of samples the decoder needs to output before the decoder\u0026#39;s output is valid. When seeking, you should start decoding this many samples prior to your desired seek point.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_set_codec_descriptor","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetCodecDescriptor","doc":"\u003cp\u003e\nSetCodecDescriptor sets the CodecDescriptor.\nC-Function: av_codec_set_codec_descriptor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::initial_padding","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::InitialPadding","doc":"\u003cp\u003e\nInitialPadding returns the amount of padding (in samples) inserted by the encoder at the beginning of the audio. I.e. this number of leading decoded samples must be discarded by the caller to get the original audio without leading padding.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::initial_padding\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::sample_aspect_ratio","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::SampleAspectRatio","doc":"\u003cp\u003e\nSampleAspectRatio returns the aspect ratio (width / height) which a single pixel should have when displayed.\n\u003c/p\u003e\n\u003cp\u003e\nWhen the aspect ratio is unknown / undefined, the numerator should be set to 0 (the denominator may have any value).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::sample_aspect_ratio\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_version","goRep":[{"name":"ffgopeg/avfilter.Version","doc":"\u003cp\u003e\nVersion returns the LIBAVFILTER_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse2","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::Parse2","doc":"\u003cp\u003e\nParse2 adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse2\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_register","goRep":[{"name":"ffgopeg/avcodec.RegisterCodec","doc":"\u003cp\u003e\nRegisterCodec registers the codec and initializes libavcodec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_register\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_unpack_dictionary","goRep":[{"name":"ffgopeg/avcodec.UnpackDictionary","doc":"\u003cp\u003e\nUnpackDictionary unpacks a dictionary from side_data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_unpack_dictionary\n\u003c/p\u003e\n"}]},{"ffmpeg":"swscale_version","goRep":[{"name":"ffgopeg/swscale.Version","doc":"\u003cp\u003e\nVersion returns the LIBSWSCALE_VERSION_INT constant.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function:\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swscale_version\n\u003c/p\u003e\n"}]},{"ffmpeg":"avformat_configuration","goRep":[{"name":"ffgopeg/avformat.Configuration","doc":"\u003cp\u003e\nConfiguration returns the libavformat build-time configuration.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avformat_configuration\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_append_packet","goRep":[{"name":"ffgopeg/avformat.IOContext::AvAppendPacket","doc":"\u003cp\u003e\nRead data and append it to the current content of the Packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_append_packet\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::","goRep":[{"name":"ffgopeg/avcodec.Packet::SideData","doc":"\u003cp\u003e\nSideData returns the side data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_link","goRep":[{"name":"ffgopeg/avfilter.Link","doc":"\u003cp\u003e\nLink links two filters together.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_link\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_default_get_format","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DefaultGetFormat","doc":"\u003cp\u003e\nDefaultGetFormat is undocumented...\nC-Function: avcodec_default_get_format\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::refcounted_frames","goRep":[{"name":"ffgopeg/avcodec.CodecContext::RefcountedFrames","doc":"\u003cp\u003e\nRefcountedFrames returns the number of references of audio and video frames.\n\u003c/p\u003e\n\u003cp\u003e\nIf non-zero, the decoded audio and video frames returned from avcodec_decode_video2() and avcodec_decode_audio4() are reference-counted and are valid indefinitely.\n\u003c/p\u003e\n\u003cp\u003e\nThe caller must free them with av_frame_unref() when they are not needed anymore. Otherwise, the decoded frames must not be freed by the caller and are only valid until the next decode call.\n\u003c/p\u003e\n\u003cp\u003e\nThis is always automatically enabled if avcodec_receive_frame() is used.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refcounted_frames\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_output_timestamp","goRep":[{"name":"ffgopeg/avformat.FormatContext::OutputTimestamp","doc":"\u003cp\u003e\nOutputTimestamp returns timing information for the data currently output.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_output_timestamp\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_seek_preroll","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SeekPreroll","doc":"\u003cp\u003e\nSeekPreroll returns something undocumented.\nC-Function: av_codec_get_seek_preroll\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_output_video_device_next","goRep":[{"name":"ffgopeg/avdevice.OutputVideoDevices","doc":"\u003cp\u003e\nOutputVideoDevices returns a channel which can be used to iterate over the output video devices.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor d := range avdevice.OutputVideoDevices() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: av_output_video_device_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::me_sub_cmp","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MeSubCmp","doc":"\u003cp\u003e\nMeSubCmp returns the subpixel motion comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_sub_cmp\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMeSubCmp","doc":"\u003cp\u003e\nSetMeSubCmp sets the subpixel motion comparison function.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::me_sub_cmp\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::refs","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Refs","doc":"\u003cp\u003e\nRefs returns the number reference frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refs\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetRefs","doc":"\u003cp\u003e\nSetRefs sets the number reference frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::refs\n\u003c/p\u003e\n"}]},{"ffmpeg":"avdevice_license","goRep":[{"name":"ffgopeg/avdevice.License","doc":"\u003cp\u003e\nLicense returns the libavdevice license.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avdevice_license\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_new_side_data","goRep":[{"name":"ffgopeg/avutil.Frame::NewSideData","doc":"\u003cp\u003e\nNewSideData adds a new side data to a frame.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_new_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_inject_silence","goRep":[{"name":"ffgopeg/swresample.Context::InjectSilence","doc":"\u003cp\u003e\nInjectSilence injects the specified number of silence samples.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_inject_silence\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::i_quant_offset","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IQuantOffset","doc":"\u003cp\u003e\nIQuantOffset returns the qscale offset between P and I-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_offset\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetIQuantOffset","doc":"\u003cp\u003e\nSetIQuantOffset sets the qscale offset between P and I-frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_offset\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::mb_lmin","goRep":[{"name":"ffgopeg/avcodec.CodecContext::MbLMin","doc":"\u003cp\u003e\nMbLMin returns the minimum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmin\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetMbLMin","doc":"\u003cp\u003e\nSetMbLMin returns the minimum MB Lagrange multiplier.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::mb_lmin\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_free_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::FreeSideData","doc":"\u003cp\u003e\nFreeSideData is a convenience function to free all the side data stored.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_free_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::side_data_elems","goRep":[{"name":"ffgopeg/avcodec.Packet::SideDataElems","doc":"\u003cp\u003e\nSideDataElems returns something undefined...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::side_data_elems\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_get_filter","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::Filter","doc":"\u003cp\u003e\nFilter retursn a filter instance identified by instance name from graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_get_filter\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_write_trailer","goRep":[{"name":"ffgopeg/avformat.FormatContext::WriteTrailer","doc":"\u003cp\u003e\nWriteTrailer writes the stream trailer to an output media file and free the file private data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_write_trailer\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::bits_per_coded_sample","goRep":[{"name":"ffgopeg/avcodec.CodecContext::BitsPerCodedSample","doc":"\u003cp\u003e\nBitsPerCodedSample returns the bits per sample/pixel from the demuxer (needed for huffyuv).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_coded_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetBitsPerCodedSample","doc":"\u003cp\u003e\nSetBitsPerCodedSample set the bits per sample/pixel from the demuxer (needed for huffyuv).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::bits_per_coded_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::i_quant_factor","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IQuantFactor","doc":"\u003cp\u003e\nIQuantFactor returns the qscale factor between P- and I-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q * factor + offset).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_factor\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetIQuantFactor","doc":"\u003cp\u003e\nSetIQuantFactor sets the qscale factor between P- and I-frames.\nIf \u0026gt; 0 then the last P-frame quantizer will be used (q = lastp_q * factor + offset).\nIf \u0026lt; 0 then normal ratecontrol will be done (q = -normal_q * factor + offset).\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::i_quant_factor\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::color_trc","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ColorTrc","doc":"\u003cp\u003e\nColorTrc returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::color_trc\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_parse","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::Parse","doc":"\u003cp\u003e\nParse adds a graph described by a string to a graph.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_parse\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_probe_input_buffer2","goRep":[{"name":"ffgopeg/avformat.IOContext::ProbeInputBuffer","doc":"\u003cp\u003e\nProbeInputBuffer probes a bytestream to determine the input format.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_probe_input_buffer2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_bytes_per_sample","goRep":[{"name":"ffgopeg/avutil.SampleFormat::BytesPerSample","doc":"\u003cp\u003e\nBytesPerSample returns the bytes per sample.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bytes_per_sample\n\u003c/p\u003e\n"},{"name":"ffgopeg/avutil.SampleFormat::IsPlanar","doc":"\u003cp\u003e\nIsPlanar returns true if the format is planar.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_bytes_per_sample\n\u003c/p\u003e\n"}]},{"ffmpeg":"swr_close","goRep":[{"name":"ffgopeg/swresample.Context::Close","doc":"\u003cp\u003e\nClose closes the context so that swr_is_initialized() returns 0.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: swr_close\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::intra_dc_precision","goRep":[{"name":"ffgopeg/avcodec.CodecContext::IntraDcPrecision","doc":"\u003cp\u003e\nIntraDcPrecision returns the precision of the intra DC coefficient - 8.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::intra_dc_precision\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetIntraDcPrecision","doc":"\u003cp\u003e\nSetIntraDcPrecision sets the precision of the intra DC coefficient - 8.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::intra_dc_precision\n\u003c/p\u003e\n"}]},{"ffmpeg":"avcodec_get_type","goRep":[{"name":"ffgopeg/avcodec.CodecId::Type","doc":"\u003cp\u003e\nType returns the type of the codec.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avcodec_get_type\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_next","goRep":[{"name":"ffgopeg/avfilter.Filters","doc":"\u003cp\u003e\nFilters returns a channel which can be used to iterate over the filters.\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor f := range avdevice.Filters() {\n    // ...\n}\n\u003c/pre\u003e\n\u003cp\u003e\nC-Function: avfilter_next\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_config_links","goRep":[{"name":"ffgopeg/avfilter.FilterContext::ConfigLinks","doc":"\u003cp\u003e\nConfigLinks negotiates the media format, dimensions, etc of all inputs to a filter.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_config_links\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_pkt_dump_log2","goRep":[{"name":"ffgopeg/avformat.AvPktDumpLog2","doc":"\u003cp\u003e\nSend a nice dump of a packet to the log.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_pkt_dump_log2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_frame_get_plane_buffer","goRep":[{"name":"ffgopeg/avutil.Frame::PlaneBuffer","doc":"\u003cp\u003e\nPlaneBuffer gets the buffer reference a given data plane is stored in.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_frame_get_plane_buffer\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sample_aspect_ratio","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SampleAspectRatio","doc":"\u003cp\u003e\nSampleAspectRatio returns the sample aspect ratio.\n\u003c/p\u003e\n\u003cp\u003e\nsample aspect ratio (0 if unknown) That is the width of a pixel divided by the height of the pixel.\n\u003c/p\u003e\n\u003cp\u003e\nNumerator and denominator must be relatively prime and smaller than 256 for some video standards.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_aspect_ratio\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetSampleAspectRatio","doc":"\u003cp\u003e\nSetSampleAspectRatio sets the sample aspect ratio.\n\u003c/p\u003e\n\u003cp\u003e\nsample aspect ratio (0 if unknown) That is the width of a pixel divided by the height of the pixel.\n\u003c/p\u003e\n\u003cp\u003e\nNumerator and denominator must be relatively prime and smaller than 256 for some video standards.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_aspect_ratio\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::slice_flags","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SetSliceFlags","doc":"\u003cp\u003e\nSetSliceFlags sets the slice flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_flags\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SliceFlags","doc":"\u003cp\u003e\nSliceFlags returns the slice flags.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::slice_flags\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_parser_parse2","goRep":[{"name":"ffgopeg/avcodec.CodecContext::Parse","doc":"\u003cp\u003e\nParse is not yet completely implemented.\nC-Function: av_parser_parse2\nTODO\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_pkt_timebase","goRep":[{"name":"ffgopeg/avcodec.CodecContext::PktTimebase","doc":"\u003cp\u003e\nPktTimebase returns the packet timebase.\nC-Function: av_codec_get_pkt_timebase\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::sample_rate","goRep":[{"name":"ffgopeg/avcodec.CodecContext::SampleRate","doc":"\u003cp\u003e\nSampleRate returns the number of samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_rate\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetSampleRate","doc":"\u003cp\u003e\nSetSampleRate sets the number of samples per second.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::sample_rate\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::video_delay","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::VideoDelay","doc":"\u003cp\u003e\nVideoDelay returns the number of delayed frames.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::video_delay\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacket::pts","goRep":[{"name":"ffgopeg/avcodec.Packet::Pts","doc":"\u003cp\u003e\nPts returns the presentation timestamp in AVStream-\u0026gt;time_base units; the time at which the decompressed packet will be presented to the user.\n\u003c/p\u003e\n\u003cp\u003e\nCan be AV_NOPTS_VALUE if it is not stored in the file. pts MUST be larger or equal to dts as presentation cannot happen before decompression, unless one wants to view hex dumps. Some formats misuse the terms dts and pts/cts to mean something different. Such timestamps must be converted to true pts/dts before they are stored in AVPacket.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::pts\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_packet_get_side_data","goRep":[{"name":"ffgopeg/avcodec.Packet::SideDataOfType","doc":"\u003cp\u003e\nSideDataOfType get side information from packet.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_packet_get_side_data\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_fast_padded_mallocz","goRep":[{"name":"ffgopeg/avcodec.FastPaddedMallocz","doc":"\u003cp\u003e\nFastPaddedMallocz allocates a buffer, reusing the given one if large enough and initializes the data with 0.\nThe buffer has additional FF_INPUT_BUFFER_PADDING_SIZE at the end which will always be 0.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_fast_padded_mallocz\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_hwaccel_next","goRep":[{"name":"ffgopeg/avcodec.RegisteredHWAccels","doc":"\u003cp\u003e\nRegisteredHWAccels returns a channel which can be used to iterate over the registered HWAccel.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_hwaccel_next\n\u003c/p\u003e\n\u003cp\u003e\nUsage:\n\u003c/p\u003e\n\u003cpre\u003efor hwa := range avcodec.RegisteredHWAccels() {\n    // ...\n}\n\u003c/pre\u003e\n"}]},{"ffmpeg":"AVPacket::buf","goRep":[{"name":"ffgopeg/avcodec.Packet::Buf","doc":"\u003cp\u003e\nBuf returns a reference to the reference-counted buffer where the packet data is stored.\nMay be nil, then the packet data is not reference-counted.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacket::buf\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVPacketSideData::data","goRep":[{"name":"ffgopeg/avcodec.PacketSideData::Data","doc":"\u003cp\u003e\nData returns the data.\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVPacketSideData::data\n\u003c/p\u003e\n"}]},{"ffmpeg":"avfilter_graph_queue_command","goRep":[{"name":"ffgopeg/avfilter.FilterGraph::QueueCommand","doc":"\u003cp\u003e\nQueueCommand queues a command for one or more filter instances.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: avfilter_graph_queue_command\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_codec_get_tag2","goRep":[{"name":"ffgopeg/avformat.AvCodecGetTag2","doc":"\u003cp\u003e\nGet the codec tag for the given codec id.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_codec_get_tag2\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_interleaved_write_uncoded_frame","goRep":[{"name":"ffgopeg/avformat.FormatContext::InterleavedWriteUncodedFrame","doc":"\u003cp\u003e\nInterleavedWriteUncodedFrame writes a uncoded frame to an output media file.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_interleaved_write_uncoded_frame\n\u003c/p\u003e\n"}]},{"ffmpeg":"av_get_sample_fmt_name","goRep":[{"name":"ffgopeg/avutil.SampleFormat::Name","doc":"\u003cp\u003e\nName returns the sample format name.\n\u003c/p\u003e\n\u003cp\u003e\nC-Function: av_get_sample_fmt_name\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecContext::dark_masking","goRep":[{"name":"ffgopeg/avcodec.CodecContext::DarkMasking","doc":"\u003cp\u003e\nDarkMasking returns the darkness masking (0 means \u0026#34;disabled\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dark_masking\n\u003c/p\u003e\n"},{"name":"ffgopeg/avcodec.CodecContext::SetDarkMasking","doc":"\u003cp\u003e\nSetDarkMasking sets the darkness masking (0 means \u0026#34;disabled\u0026#34;)\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecContext::dark_masking\n\u003c/p\u003e\n"}]},{"ffmpeg":"AVCodecParameters::chroma_location","goRep":[{"name":"ffgopeg/avcodec.CodecParameters::ChromaLocation","doc":"\u003cp\u003e\nChromaLocation returns something undocumented...\n\u003c/p\u003e\n\u003cp\u003e\nC-Field: AVCodecParameters::chroma_location\n\u003c/p\u003e\n"}]}];
